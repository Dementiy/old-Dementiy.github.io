<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Заметки по нейронным сетям</title>
  <meta name="description" content="Эта заметка является вольным переводом статьи Deep Neural Network from scratch и является пререквизитом к выполнению работы Нейронная сеть для распознования рукописных цифр.">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://dementiy.github.io/2017/11/22/notes-on-neuralnetworks/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Ein Blog für freie Geister" href="https://dementiy.github.io/feed.xml">

  <link rel="icon" type="image/x-icon" href="/favicon.ico">


  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="Заметки по нейронным сетям">
  <meta name="twitter:description" content="Эта заметка является вольным переводом статьи Deep Neural Network from scratch и является пререквизитом к выполнению работы Нейронная сеть для распознования рукописных цифр.">
  
  

  <script type="text/javascript">
  WebFontConfig = {
    google: { families: [ 'Bitter:400,700,400italic:latin' ] }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  
  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-111461883-1', 'auto');
    ga('send', 'pageview');

  </script>


</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Ein Blog für freie Geister</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/practice/">Py&Go Practice</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
        
        <a class="page-link" href="https://github.com/Dementiy/">GitHub</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
      <h1 class="post-title" itemprop="name headline">Заметки по нейронным сетям</h1>
    
    <p class="post-meta"><time datetime="2017-11-22T00:00:00+03:00" itemprop="datePublished">Nov 22, 2017</time> • 
  
  
    
      <a href="/categories/python/">python</a>,
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

  
  
    
  
    
      <a href="/categories/datascience/">datascience</a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  

</p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>Эта заметка является вольным переводом статьи <a href="https://matrices.io/deep-neural-network-from-scratch/">Deep Neural Network from scratch</a> и является пререквизитом к выполнению работы <a href="">Нейронная сеть для распознования рукописных цифр</a>.</p>

<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<h3 id="подготовка-данных">Подготовка данных</h3>

<p>Первым шагом является нормализация данных (feature scaling). Мы будем работать со следующими данными:</p>

<ul>
  <li>Пробег автомобиля: количественный признак, число в промежутке от 0 до 350 тысяч км.;</li>
  <li>Тип топлива: бинарный признак, который принимает значения дизель/бензин;</li>
  <li>Возраст машины: количественный признак, число в промежутке от 0 до 40;</li>
  <li>Цена: количественный признак, число в промежутке от 0 до 40 тысяч.</li>
</ul>

<p>Пробег автомобиля и возраст мы нормализуем используя среднее (mean) и стандартное отклонение (standard deviation). Целью является привести все данные к единой шкале, как правило к промежутку [-6;6]. Следует заметить, что так как пробег автомобиля принимает значения до 350 тысяч км., а возраст до 40 лет, то изменения в значении весов будут оказывать разное влияние на пробег автомобиля и его возраст. Формула для нормализации следующая:</p>

<script type="math/tex; mode=display">x' = \frac{x-\bar{x}}{\sigma}</script>

<p>Где <script type="math/tex">x</script> исходный набор данных (все машины), <script type="math/tex">\bar{x}</script> является средним значением в этом наборе данных, а <script type="math/tex">\sigma</script> стандартным отклонением в этом наборе данных. Позже мы проделаем эти шаги на Python.</p>

<p>Тип топлива (бинарный признак) будет закодирован с помощью <script type="math/tex">-1</script> для одного типа и <script type="math/tex">+1</script> для другого. В нашем примере нет категориальных данных, чтобы сохранить признаки простыми, так как в противном случае нам пришлось бы представить каждый категориальный признак в виде разреженной матрицы с числом столбцов равным количеству возможных классов (значений). Если среди ваших признаков есть категориальные данные (например, какой-то признак может принимать следующие значения: «красный», «зеленый», «розовый» и «голубой»), то вы должны использовать <a href="https://visualstudiomagazine.com/articles/2013/07/01/neural-network-data-normalization-and-encoding.aspx">effect encoding или dummy encoding</a>.</p>

<p>Мы нормализуем цены на автомобили, так чтобы все значения находились в промежутке <script type="math/tex">[0, 1]</script>. Это необходимый шаг, потому что наша нейронная сеть будет выдавать значения именно в этом промежутке. Если нейронная сеть прогнозирует, что цена автомобиля <script type="math/tex">0.45</script>, в то время как действительная цена 17 тысяч, то ошибка между прогнозом и действительной ценой будет огромной - <script type="math/tex">16 999.55€</script>. Если прогноз составит <script type="math/tex">1</script>, то ошибка будет <script type="math/tex">16 999€</script> и никогда не уменьшится. Цены мы будем нормализовать по следующей формуле:</p>

<script type="math/tex; mode=display">\frac{x_i - min(x)}{max(x) - min(x)}</script>

<p>где <script type="math/tex">x_i</script> это цена <script type="math/tex">i</script>-го автомобиля, а <script type="math/tex">x</script> все цены в наборе данных. Таким образом, нормализация цены для каждого автомобиля включает в себя использование максимальной и минимальной цен в наборе данных.</p>

<p>Итак, если после нормализации исходная цена <script type="math/tex">17</script> тысяч примет значение <script type="math/tex">0.43</script>, а наша нейросеть прогнозировала <script type="math/tex">0.45</script>, то это уже будет неплохим прогнозом, так как ошибка составит всего <script type="math/tex">0.02</script>. После того как мы получили прогноз, необходимо проделать обратные шаги в соответствии с приведенной выше формулой, чтобы получить значение цены из <script type="math/tex">0.45</script>.</p>

<h3 id="forward-propagation">Forward propagation</h3>

<p>Итак, у нас есть три входных признака (features): один бинарный, два количественных и одно количественное значение на выходе. Так как мы будем прогнозировать количественное значение, обучая нашу нейронную сеть на исторических данных (прошлых наблюдениях), то решаемая задача относится к классу задач обучения с учителем (supervised regression problem).</p>

<p><img src="/assets/images/notes-on-nn/DNN-S1-1.png" alt="" /></p>

<p>Пример одного наблюдения:</p>

<table>
  <thead>
    <tr>
      <th>Пробег автомобиля</th>
      <th>Тип топлива</th>
      <th>Возраст</th>
      <th>Цена</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>38000</td>
      <td>Gasoline</td>
      <td>3</td>
      <td>17 000</td>
    </tr>
  </tbody>
</table>

<p>После того как данные были нормализованны и закодированны так как было описано ранее, то мы получим:</p>

<table>
  <thead>
    <tr>
      <th>Пробег автомобиля</th>
      <th>Тип топлива</th>
      <th>Возраст</th>
      <th>Цена</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.4</td>
      <td>-1</td>
      <td>0.4</td>
      <td>0.45</td>
    </tr>
  </tbody>
</table>

<p>Пример для множества наблюдений:</p>

<table>
  <thead>
    <tr>
      <th>Пробег автомобиля</th>
      <th>Тип топлива</th>
      <th>Возраст</th>
      <th>Цена</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1.4</td>
      <td>-1</td>
      <td>0.4</td>
      <td>0.45</td>
    </tr>
    <tr>
      <td>0.4</td>
      <td>-1</td>
      <td>0.1</td>
      <td>0.52</td>
    </tr>
    <tr>
      <td>5.4</td>
      <td>-1</td>
      <td>4</td>
      <td>0.25</td>
    </tr>
    <tr>
      <td>1.5</td>
      <td>-1</td>
      <td>1</td>
      <td>0.31</td>
    </tr>
    <tr>
      <td>…</td>
      <td>…</td>
      <td>…</td>
      <td>…</td>
    </tr>
  </tbody>
</table>

<p>Мы можем представить этот массив в виде матрицы:</p>

<script type="math/tex; mode=display">% <![CDATA[
X = \begin{bmatrix}
	1.4 & -1 & 0.4 & 0.45 \\
	0.4 & -1 & 0.1 & 0.52 \\
	5.4 & -1 & 4 & 0.25 \\
	1.5 & -1 & 1 & 0.31 \\
	... & ... & ... & ...
\end{bmatrix} %]]></script>

<p>Значение цены не является признаком и неизвестно для новых машин, поэтому мы можем отделить входы (матрица признаков) от выходов (вектор ответов):</p>

<script type="math/tex; mode=display">% <![CDATA[
X = \begin{bmatrix}
	1.4 & -1 & 0.4 \\
	0.4 & -1 & 0.1 \\
	5.4 & -1 & 4   \\
	1.5 & -1 & 1   \\
	... & ... & ...
\end{bmatrix}

y = \begin{bmatrix}
0.45 \\
0.52 \\
0.25 \\
0.31 \\
...
\end{bmatrix} %]]></script>

<p>Итак, мы имеем две матрицы <script type="math/tex">X</script> и <script type="math/tex">y</script>, настало время завершить нашу сеть. Мы добавим два скрытых слоя (hidden layers) между входами и выходами (входной и выходной слои). В первом скрытом слое будет три нейрона, а во втором два. Количество скрытых слоев и нейронов в них зависит от вашего выбора. Это два гиперпараметра, которые вы должны выбрать прежде чем начать обучать вашу нейронную сеть.</p>

<p><img src="/assets/images/notes-on-nn/DNN-S2-1.png" alt="" /></p>

<p>Каждый входной нейрон будет иметь связь со всеми нейронами в следущем слое, так как мы используем полносвязанную сеть (fully connected network). Каждая связь между двумя нейронами называется <strong>синапсом</strong> и имеет вес. Вес синапса будем записывать в виде <script type="math/tex">W^l_{jk}</script>, где <script type="math/tex">l</script> указывает на номер слоя, <script type="math/tex">j</script> на номер нейрона в <script type="math/tex">l</script>-ом слое, а <script type="math/tex">k</script> на номер нейрона в <script type="math/tex">(l+1)</script>-ом слое.</p>

<p><img src="/assets/images/notes-on-nn/DNN-S3-1.png" alt="" /></p>

<p>Мы можем записать все веса в виде матрицы:</p>

<script type="math/tex; mode=display">% <![CDATA[
W^1 = \begin{bmatrix}
	W^1_{11} & W^1_{12} & W^1_{13} \\
	W^1_{21} & W^1_{22} & W^1_{23} \\
	W^1_{31} & W^1_{32} & W^1_{33}
\end{bmatrix} %]]></script>

<div class="admonition legend">
  <p class="first admonition-title"><strong>Замечание</strong></p>
  <p class="last">Пока не будем говорить про смещение (bias), чтобы не усложнять.</p>
</div>

<p>Число строк равно количеству признаков, а количество колонок равно количеству нейронов в втором слое (первом скрытом слое). Так как у нас три признака и три нейрона во втором слое, то соответственно матрица весов <script type="math/tex">W^1</script> будет иметь размерность <script type="math/tex">3 \times 3</script>.</p>

<p>Теперь вычислим значения нейронов в первом скрытом слое (на рисунке это первая колонка с зелеными кружками). Для каждого наблюдения (которое характеризуется тремя признаками), нам нужно вычислить значения для трех нейронов в первом скрытом слое. Для этого воспользуемся матричным исчислением.</p>

<p>Предположим, что в нашем наборе данных есть только одно наблюдение. И мы пока можем не брать во внимание значение цены (<script type="math/tex">y</script>).</p>

<script type="math/tex; mode=display">X = [1.4\quad -1\quad 0.4]</script>

<p>Матрица весов <script type="math/tex">W^1</script> первый раз инициализируется случайными значениями:</p>

<script type="math/tex; mode=display">% <![CDATA[
W^1 = \begin{bmatrix}
	0.01 & 0.05 & 0.07 \\
	0.20 & 0.041 & 0.11 \\
	0.04 & 0.56 & 0.13
\end{bmatrix} %]]></script>

<div class="admonition legend">
  <p class="first admonition-title"><strong>Замечание</strong></p>
  <p class="last">Интуитивное понимание того, что означают матрицы <code>Z</code> и <code>a</code> можно найти в первой главе книги Michael Nielsen <a href="http://neuralnetworksanddeeplearning.com/chap1.html">«Нейронные сети и глубокое обучение»</a>.</p>
</div>
<p>Значения нейронов первого скрытого слоя называются <strong>значениями активации</strong> (activities) первого скрытого слоя. Эти значения мы будем хранить в матрице с обозначением <script type="math/tex">a^{(2)}</script>. Начнем с вычисления <script type="math/tex">Z^{(2)}</script> по следующей формуле:</p>

<script type="math/tex; mode=display">Z^{(2)} = X.W^1</script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(2)} = [1.4\quad -1\quad 0.4].\begin{bmatrix}
	0.01 & 0.05 & 0.07 \\
	0.20 & 0.041 & 0.11 \\
	0.04 & 0.56 & 0.13
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">Z^{(2)} = [-0.17\quad 0.253\quad 0.04]</script>

<p>Покажем это на нашем рисунке:</p>

<p><img src="/assets/images/notes-on-nn/DNN-S4-1.png" alt="" /></p>

<p>Мы практически закончили с первым скрытым слоем, осталось только применить функцию активации к <script type="math/tex">Z^{(2)}</script>:</p>

<p><img src="/assets/images/notes-on-nn/DNN-S5.png" alt="" /></p>

<p>После того как мы применили функцию активации к каждому элементу матрицы <script type="math/tex">Z^{(2)}</script> мы получили <script type="math/tex">a^{(2)}</script> - значения активации второго слоя.</p>

<script type="math/tex; mode=display">a^{(2)}=\sigma(Z^{(2)})</script>

<p>Где <script type="math/tex">\sigma(x)</script> является функцией активации. Функция активации применяется поэлементно и не является линейной, тем самым позволяя сети решать сложные задачи, используя небольшое количество узлов (нейронов). Одними из распространенных функций активации являются: сигмоида (Sigmoid), гиперболический тангенс (Tanh), ReLU, Leaky ReLU, Maxout. На самом деле список гораздо больше. Какую функцию активации следует выбрать? Андрей Карпатый (Andrej Karpathy) говорит следующее:</p>

<blockquote>
  <p>TLDR: «What neuron type should I use?» Use the ReLU non-linearity, be careful with your learning rates and possibly monitor the fraction of «dead» units in a network. If this concerns you, give Leaky ReLU or Maxout a try. Never use sigmoid. Try tanh, but expect it to work worse than ReLU/Maxout.</p>
</blockquote>

<p>Итак, нам следовало бы выбрать ReLU (сокарщение от «rectified linear unit») в качестве функции активации: если <script type="math/tex">x</script> больше 0, то оставляем значение <script type="math/tex">x</script>, иначе 0.</p>

<script type="math/tex; mode=display">\sigma(x) = max(0, x)</script>

<p>Так как в нашей сети нейронов не так много, то один или два мертвых нейрона могут негативно сказаться на ее работе (в том случае, когда значения нейронов станут равны нулю), поэтому в качестве функции активации мы бдуем использовать гиперболический тангенс.</p>

<script type="math/tex; mode=display">\sigma(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}</script>

<p>Значение первого нейрона в первом скрытом слое будет:</p>

<script type="math/tex; mode=display">\sigma(-0.17) = tanh(-0.17) = \frac{e^{-0.17} - e^{0.17}}{e^{-0.17} + e^{0.17}} = -0.168</script>

<p>Значение второго нейрона:</p>

<script type="math/tex; mode=display">\sigma(0.253) = tanh(0.253) = \frac{e^{0.253} - e^{-0.253}}{e^{0.253} + e^{-0.253}} = 0.248</script>

<p>Итак, значения в первом скрытом слое для одного наблюдения будут следующими:</p>

<p><img src="/assets/images/notes-on-nn/DNN-S6.png" alt="" /></p>

<p><span style="color: red;">Thanks to the matrix calculus property, each neuron of the first hidden layer will receive a weighted sum of the inputs. We have</span>:</p>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(2)} = [1.4\quad -1\quad 0.4].\begin{bmatrix}
	0.01 & 0.05 & 0.07 \\
	0.20 & 0.041 & 0.11 \\
	0.04 & 0.56 & 0.13
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">Z^{(2)} = [-0.17\quad 0.253\quad 0.04]</script>

<p><script type="math/tex">Z^{(2)}_1</script> значение первого нейрона во втором слое (первом скрытом слое) равное <script type="math/tex">−0.17</script>, которое мы нашли как <script type="math/tex">1.4 \times 0.01 + −1 \times 0.2 + 0.4 \times 0.04</script> (cf Matrix Multiplication). Если вы сравните это с диаграммой нейронной сети, то заметите тот факт, что первый нейрон второго слоя имеет значение равное признаку 1 (пробег автомобиля, км.) умноженному на вес синапса, плюс значения второго признака (тип топлива) умноженного на вес синапса, плюс значение признака 3 (возраст) умноженного на вес синапса. Это именно то, что мы получаем используя матричное исчисление.</p>

<p>Пока мы рассматривали пример только для одного наблюдения <script type="math/tex">X = [1.4\quad −1\quad 0.4]</script>. В действительности же мы имеем дело с гораздо большим числом наблюдений. Для примера предположим, что у нас есть пять наблюдений и пусть наша матрица признаков (входов) будет следующей:</p>

<script type="math/tex; mode=display">% <![CDATA[
X = \begin{bmatrix}
	1.4 & -1 & 0.4 \\
	0.4 & -1 & 0.1 \\
	5.4 & -1 & 4   \\
	1.5 & -1 & 1   \\
	1.8 & 1 & 1
\end{bmatrix} %]]></script>

<p>Тогда значения для <script type="math/tex">Z^{(2)}</script> будут следующими:</p>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(2)} = \begin{bmatrix}
	1.4 & -1 & 0.4 \\
	0.4 & -1 & 0.1 \\
	5.4 & -1 & 4   \\
	1.5 & -1 & 1   \\
	1.8 & 1 & 1
\end{bmatrix} . \begin{bmatrix}
	0.01 & 0.05 & 0.07 \\
	0.20 & 0.041 & 0.11 \\
	0.04 & 0.56 & 0.13
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(2)} = \begin{bmatrix}
	-0.17  & 0.253 & 0.04 \\
	-0.192 & 0.035 & -0.069 \\
	0.014  & 2.469 & 0.788   \\
	-0.145 & 0.594 & 0.125   \\
	0.258  & 0.691 & 0.366
\end{bmatrix} %]]></script>

<p>Применив поэлементно функцию активации (гиперболический тангенс) получим:</p>

<script type="math/tex; mode=display">% <![CDATA[
a^{(2)} = \sigma(Z^{(2)}) = tanh(Z^{(2)}) = \begin{bmatrix}
	tanh(-0.17)  & tanh(0.253) & tanh(0.04) \\
	tanh(-0.192) & tanh(0.035) & tanh(-0.069) \\
	tanh(0.014)  & tanh(2.469) & tanh(0.788)   \\
	tanh(-0.145) & tanh(0.594) & tanh(0.125)   \\
	tanh(0.258)  & tanh(0.691) & tanh(0.366)
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
a^{(2)} = \begin{bmatrix}
	-0.16838105 & 0.24773663 & 0.03997868 \\
	-0.18967498 & 0.03498572 & -0.06889071 \\
	0.01399909 & 0.98576421 & 0.65727455 \\
	-0.14399227 & 0.53276635 & 0.124353 \\
	0.25242392 & 0.59862403 & 0.35048801
\end{bmatrix} %]]></script>

<p><script type="math/tex">Z^{(2)}</script> и <script type="math/tex">a^{(2)}</script> имеют размерности <script type="math/tex">5 \times 3</script>, каждая строка соответствует одному наблюдению, а столбцы соответствуют нейронам в первом скрытом слое.</p>

<p>Итак, у нас есть три матрицы: матрица признаков (или входов) <script type="math/tex">X</script>, матрица весов <script type="math/tex">W^1</script> между первым и вторым слоем, и матрица значений активации для первого скрытого слоя <script type="math/tex">a^{(2)} = tanh(X.W^1)</script> (<script type="math/tex">Z^{(2)}</script> является промежуточной матрицей и содержит значения <script type="math/tex">X.W^1</script>).</p>

<p><img src="/assets/images/notes-on-nn/DNN-S7-1.png" alt="" /></p>

<p>Для вычисления значений активации во втором скрытом слое мы будем повторять теже самые шаги, но вместо матрицы <script type="math/tex">X</script> мы будем использовать матрицу <script type="math/tex">a^{(2)}</script> в качестве входов. Также добавим синапсы (связи) от слоя 2 (первого скрытого слоя) к слою 3 (второму скрытому слою).</p>

<p><img src="/assets/images/notes-on-nn/DNN-S8-1.png" alt="" /></p>

<p>Также запишем веса в виде матрицы:</p>

<script type="math/tex; mode=display">% <![CDATA[
W^2 = \begin{bmatrix}
	W^2_{11} & W^2_{12} \\
	W^2_{21} & W^2_{22} \\
	W^2_{31} & W^2_{32}
\end{bmatrix} %]]></script>

<p>Число строк равно числу нейронов в первом скрытом слое, а число колонок числу нейронов во втором скрытом слое. Мы будем вычислять значения <script type="math/tex">Z^{(3)}</script> для второго скрытого слоя также как делали это раньше для <script type="math/tex">Z^{(2)}</script>. Можно запомнить простое правило: для некоторого слоя <script type="math/tex">l</script> входами всегда являются выходы из предыдущего слоя <script type="math/tex">l-1</script>. Например, для слоя 2 выходами предыдущего слоя являются значения из слоя 1, то есть <script type="math/tex">X</script>, для слоя 3 выходами предыдущего слоя являются значения из слоя 2, то есть <script type="math/tex">a^{(2)}</script> и т.д.</p>

<script type="math/tex; mode=display">Z^{(3)} = a^{(2)}.W^2</script>

<p>Затем мы применяем функцию активации, мы оставим <script type="math/tex">tanh(x)</script> в качестве функции активации, так как редко используют различные функции активации в разных слоях.</p>

<script type="math/tex; mode=display">a^{(3)} = tanh(Z^{(3)})</script>

<p>Ранее мы нашли, что:</p>

<script type="math/tex; mode=display">% <![CDATA[
a^{(2)} = \begin{bmatrix}
	-0.16838105 & 0.24773663 & 0.03997868 \\
	-0.18967498 & 0.03498572 & -0.06889071 \\
	0.01399909 & 0.98576421 & 0.65727455 \\
	-0.14399227 & 0.53276635 & 0.124353 \\
	0.25242392 & 0.59862403 & 0.35048801
\end{bmatrix} %]]></script>

<p>Инициализируем матрицу <script type="math/tex">W^2</script> случайными значениями:</p>

<script type="math/tex; mode=display">% <![CDATA[
W^2 = \begin{bmatrix}
	0.04 & 0.78 \\
	0.40 & 0.45 \\
	0.65 & 0.23
\end{bmatrix} %]]></script>

<p>Теперь вычислим <script type="math/tex">Z^{(3)}</script>:</p>

<script type="math/tex; mode=display">Z^{(3)}=a^{(2)}.W2</script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(3)} = \begin{bmatrix}
	-0.16838105 & 0.24773663 & 0.03997868 \\
	-0.18967498 & 0.03498572 & -0.06889071 \\
	0.01399909 & 0.98576421 & 0.65727455 \\
	-0.14399227 & 0.53276635 & 0.124353 \\
	0.25242392 & 0.59862403 & 0.35048801
\end{bmatrix} . \begin{bmatrix}
	0.04 & 0.78 \\
	0.40 & 0.45 \\
	0.65 & 0.23
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(3)} = \begin{bmatrix}
	0.11834555 & -0.01066064 \\
	-0.03837167 & -0.14804778 \\
	0.8220941 & 0.60568633 \\
	0.2881763 & 0.15603208 \\
	0.47736378 & 0.54688371
\end{bmatrix} %]]></script>

<p>Применим нашу функцию активации:</p>

<script type="math/tex; mode=display">a^{(3)} = tanh(Z^{(3)})</script>

<script type="math/tex; mode=display">% <![CDATA[
a^{(3)} = \begin{bmatrix}
	tanh(0.11834555) & tanh(-0.01066064) \\
	tanh(-0.03837167) & tanh(-0.14804778) \\
	tanh(0.8220941) & tanh(0.60568633) \\
	tanh(0.2881763) & tanh(0.15603208) \\
	tanh(0.47736378) & tanh(0.54688371)
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
a^{(3)} = \begin{bmatrix}
	0.11779613 & -0.01066023 \\
	-0.03835285 & -0.14697553 \\
	0.67620804 & 0.54108347 \\
	0.28045542 & 0.15477804 \\
	0.44412987 & 0.49818098
\end{bmatrix} %]]></script>

<p><script type="math/tex">Z^{(3)}</script> и <script type="math/tex">a^{(3)}</script> имеют размерности <script type="math/tex">5 \times 2</script>, каждая строка соответствует одному наблюдению, а столбцы соответствуют нейронам во втором скрытом слое.</p>

<p>Итак, наша нейроная сеть выглядит следюущим образом:</p>

<p><img src="/assets/images/notes-on-nn/DNN-S9.png" alt="" /></p>

<p>Теперь добавим связи к последнему слою, также как мы делали это раньше:</p>

<p><img src="/assets/images/notes-on-nn/DNN-S10-1.png" alt="" /></p>

<p>Как и для предыдущих двух слоев имеем:</p>

<script type="math/tex; mode=display">Z^{(4)} = a^{(3)}.W^3</script>

<script type="math/tex; mode=display">a^{(4)} = tanh(Z^{(4)})</script>

<p>Где:</p>

<script type="math/tex; mode=display">W^3 = \begin{bmatrix}
	W^3_{11} \\
	W^3_{21}
\end{bmatrix}</script>

<p>Число строк равно числу нейронов во втором скрытом слое, а число колонок числу нейронов в выходном слое.</p>

<p>Инициализируем матрицу <script type="math/tex">W^3</script> случайными значениями, например:</p>

<script type="math/tex; mode=display">W^3= \begin{bmatrix}
	0.04 \\
	0.41
\end{bmatrix}</script>

<p>Вычислим значения для <script type="math/tex">Z^{(4)}</script>, используя значения <script type="math/tex">a^{(3)}</script>, которые являются выходами предыдущего слоя:</p>

<script type="math/tex; mode=display">Z^{(4)} = a^{(3)}.W^3</script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(4)} = \begin{bmatrix}
	0.11779613 & -0.01066023 \\
	-0.03835285 & -0.14697553 \\
	0.67620804 & 0.54108347 \\
	0.28045542 & 0.15477804 \\
	0.44412987 & 0.49818098
\end{bmatrix}.\begin{bmatrix}
	0.04 \\
	0.41
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">Z^{(4)} = \begin{bmatrix}
	0.00034115 \\
	-0.06179408 \\
	0.24889254 \\
	0.07467721 \\
 	0.22201939
\end{bmatrix}</script>

<p>Теперь применим функцию активации:</p>

<script type="math/tex; mode=display">a^{(4)} = tanh(Z^{(4)}) = \begin{bmatrix}
	tanh(0.00034115) \\
	tanh(-0.06179408) \\
	tanh(0.24889254) \\
	tanh(0.07467721) \\
 	tanh(0.22201939)
\end{bmatrix}</script>

<script type="math/tex; mode=display">a^{(4)} = \begin{bmatrix}
	0.000341156 \\
	−0.0617156 \\
	0.243877 \\
	0.0745387 \\
 	0.218442
\end{bmatrix}</script>

<p>Наконец наша сеть выглядит следующим образом:</p>

<p><img src="/assets/images/notes-on-nn/DNN-S11.png" alt="" /></p>

<p>То что мы проделали называется <strong>forward propagation</strong>, у нас есть входные значения и мы распространяем их через сеть. На каждом скрытом слое мы вычисляем значения нейронов, используя следующую формулу:</p>

<script type="math/tex; mode=display">a^{(l)} = \sigma(a^{(l−1)} \times W^{(l−1)})</script>

<p>Если <script type="math/tex">l = 1</script>, то <script type="math/tex">a^{(1)} = X</script> (наши входы), <script type="math/tex">\sigma(x)</script> в нашем случае это <script type="math/tex">tanh(x)</script>. Каждый раз, когда вы встречаете формулу выше, вы можете думать, что это «слой нейронной сети».</p>

<h3 id="bias">Bias</h3>

<p>До сих пор мы не говорили о смещении. Зачем оно нужно? Из диаграммы выше мы можем видеть, что <script type="math/tex">Z_1^{(2)} = X_1 \times W^1_{11}+X_2 \times W^2_{11}+X_3 \times W^3_{11}</script>, где <script type="math/tex">X_1</script>, <script type="math/tex">X_2</script> и <script type="math/tex">X_3</script> это признаки (атрибуты) нашей машины (наблюдения). К результату вычисления <script type="math/tex">Z_1^{(2)}</script> мы применяем функцию активации <script type="math/tex">tanh(Z_1^{(2)})</script>. У нас есть 3D вектор (<script type="math/tex">X_1, X_2, X_3</script>), но для пояснения полезности смещения мы оставим только один признак, например, пробег автомобиля, и предположим, что этого признака достаточно для описания цены. Таким образом, мы получим <script type="math/tex">Z_1^{(2)}=X_1×W^1_{11}</script>, где <script type="math/tex">X_1</script> - пробег автомобиля. И после применения функции активации получим <script type="math/tex">a_1^{(2)} = tanh(Z_1^{(2)}) = tanh(X_1 \times W^1_{11})</script>.</p>

<p>После обучения сети (о котором мы будем говорить ниже) мы получим значение для параметра <script type="math/tex">W^1_{11}</script>. Например, <script type="math/tex">1.8</script>. Значение <script type="math/tex">X_1</script> заранее неизвестено и будет меняться от наблюдения к наблюдению, <script type="math/tex">a_1^{(2)}</script>, таким образом, будет результатом вычисления <script type="math/tex">tanh(1.8 \times X_1)</script>. Мы можем отобразить график этой функции:</p>

<p><img src="/assets/images/notes-on-nn/DNN-FUNC1.png" alt="" /></p>

<p>Как вы можете видеть эта функция отцентрована относительно нуля. <script type="math/tex">W^1_{11}</script> это то, что мы фактически обучаем, таким образом, наша сеть будет пытаться «нащупать» правильное значение. Ранее мы сделали предположение, что <script type="math/tex">W^1_{11} = 1.8</script>, но давайте отобразим график для значения <script type="math/tex">W^1_{11} = 7</script>:</p>

<p>As you can see this function is centered in zero, as our W111 is a learned value, our network will be able to tweak it. We assumed that our network learned 1.8 but let’s draw the graph when W111 is larger, let’s say 7.</p>

<p><img src="/assets/images/notes-on-nn/DNN-FUNC2.png" alt="" /></p>

<p>Или для <script type="math/tex">W^1_{11} = 0.4</script>:</p>

<p><img src="/assets/images/notes-on-nn/DNN-FUNC3.png" alt="" /></p>

<p>Можно заметить, что изменения <script type="math/tex">W^1_{11}</script> связаны с «крутостью» нашего графика, а так как обучение сети отражается только на значении весов, то … Является ли это проблемой?</p>

<p>As we can see, changing W111 changes the stiffness of the graph, as our network can only tweak the weights, it will only be able to change the stiffness but will stay centered in zero. Is this a problem ?</p>

<p>Во-первых, пробег автомобиля всегда положителен, поэтому вся левая часть графика не имеет смысла, соответственно значение <script type="math/tex">a_1^{(2)}</script> никогда не будет отрицательным. Это хорошая новость? На самом деле мы этого не знаем, но даже если так, то у нас все равно нет другого выбора.</p>

<p>Во-вторых, предположим теперь, что у нас есть два наблюдения, в одном пробег автомобиля равен 30 тысячам километров, а во втором 170 тысячам километров, после нормализации значений получим 0.5 и 2.5, соответственно. Допустим, что влияние пробега автомобиля на цену сторого детерминировано, например, если пробег меньше 50 тысяч километров, то цена высокая, в противном случае низкая. Нормализованное значение для 50 тысяч будет около 0.7, таким образом, нам нужен достаточно крутой график, который выдает значение <script type="math/tex">-1</script> при <script type="math/tex">% <![CDATA[
x < 0.7 %]]></script> и <script type="math/tex">1</script> когда <script type="math/tex">x > 0.7</script>. Ниже приведен пример такого графика:</p>

<p><img src="/assets/images/notes-on-nn/DNN-FUNC4.png" alt="" /></p>

<p>Это было бы идеально, но к сожалению мы не можем подвинуть график вправо, поэтому застраляи с графиком отцентрованным относительно нуля (первое изображение). Мы можем только сделать график более крутым, используя более высокие значения для <script type="math/tex">W^1_{11}</script>. Рисунок выше был бы отличным решением для нас, функция для которого:</p>

<p>That would be perfect but unfortunately we can’t move the graph to the right, so we are stuck with a graph centered in zero (the first image). We can only make the graph steep using a high value for W111. The above picture would be a good solution for us, it is the graph of the function:</p>

<script type="math/tex; mode=display">tanh(10x−8)</script>

<p>Где <script type="math/tex">10</script> это значение для <script type="math/tex">W^1_{11}</script>, а <script type="math/tex">8</script> является подходящей константой - смещением. Теперь вместо <script type="math/tex">a_1^{(2)} = tanh(X_1 \times W^1_{11})</script> мы можем записать <script type="math/tex">a_1^{(2)} = tanh(X_1 \times W^1_{11} + b)</script>, и это маленькое <script type="math/tex">b</script> сильно улучшает проивзодительной нашей сети, так как позволяет сдвинуть график нашей функции влево или вправо, таким образом, позволяя получить более подходящий результат для нашей задачи. В нашем примере (см. рисунок выше) подходящее значение <script type="math/tex">b = −8</script>.</p>

<p>Where 10 is the value for our W111 and 8 is a constant that comes handy, the bias. Instead of a1(2)=tanh(X1×W111) we will have a1(2)=tanh(X1×W111+b) and this little b will greatly improve our network performances because it will move the graph of our activation function to the left or the right and the result produced will be more representative of our problem. In our example (the above picture) b=−8.</p>

<p>Мы использовали только один признак, чтобы было проще отобразить график и показать влияние оказываемое смещением, но все остается тем же самым, когда мы говорим о более высоких размерностях. Если к нашему исходному примеру добавить смещение, то мы получим <script type="math/tex">a_1^{(2)} = tanh(X_1 \times W^1_{11} + X_2 \times W^2_{11} + X_3 \times W^3_{11} + b)</script>.</p>

<p>We used only one feature to easily draw graphs and display the impact of the bias but it is the same thing with more dimensions, our original example with a bias would be <script type="math/tex">a1^{(2)} = tanh(X1×W111+X2×W211+X3×W311+b)</script>.</p>

<p>Значение для смещения мы также находим в процессе обучения сети, так как оно меняется в зависимости от решаемой задачи. Одно и тоже значение смещения мы должны добавить к каждому наблюдению. Ранее мы видели истоки происхождения весов и их матричное представление, но как мы должны добавить смещение?</p>

<p>Смещение будет у каждого нейрона. Например, для первого нейрона первого скрытого слоя получим:</p>

<script type="math/tex; mode=display">a_1^{(2)} = tanh(X_1 \times W^1_{11}+X_2 \times W^2_{11}+X_3 \times W^3_{11} + b)</script>

<p>Так как у нас три нейрона в первом скрытом слое, то нам нужно добавить три смещения, для этого мы можем использовать матрицу (вектор) смещений:</p>

<p><img src="/assets/images/notes-on-nn/BIAS-WITHOUT-TRICK.png" alt="" /></p>

<p>Работа со смещениями и весами представленными в виде отдельных матриц может быть довольно громоздкой. После обучения смещений… Решением является добавление нового признака со значением <script type="math/tex">1</script> к каждому наблюдению, так как такое значение для признака, при его умножении на смещение, не меняет его значения.</p>

<p>Nonetheless managing the biases and the weights in separate matrices can be cumbersome. As the biases are learned, there are not different from the weights nonetheless they should not depend of a car attributes because all the car will have different attributes whereas the biases should be the same for all the cars. The solution is to add an additional feature to each car with a value 1. So that this feature when multiplied with the bias will not change its value.</p>

<p><img src="/assets/images/notes-on-nn/BIAS-TRICK.png" alt="" /></p>

<p>Заметьте, что значения <script type="math/tex">X_4</script> равны <script type="math/tex">1</script>, таким образом, вычисления останутся прежними, но используя этот небольшой трюк, у нас будет только одна матрица весов.</p>

<p>Note that X4 is equal to 1 so the calculations of the two previous pictures are exactly the same but using the bias trick we only have one weights matrix.</p>

<p>Adding a bias means adding a 1 feature to all our inputs. We add biases to our input layer and each one of our hidden layers. Now our network looks like.</p>

<p><img src="/assets/images/notes-on-nn/DNN-S12.png" alt="" /></p>

<p>Связь между смещением и нейронами показана пунктирной линией, чтобы диаграмма сети оставалась читаемой, но это обычные веса.</p>

<p>The link between the bias and the neurons are dotted to keep the network readable but they are normal weights. Our cars have a new feature with the value 1. Each hidden layer has also a new neuron 1 because the problem that the bias solve appears each time we use the activation function (so each layer). There is no link between the bias and the previous layer because the bias is added after the calculations, it is not the result of a matrix multiplication.</p>

<p>Снова проделаем все вычисления, но в этот раз учитывая смещения. Мы начнем с того, что добавим смещения в матрицу признаков, фактически просто добавив новую колонку состоящую из единиц.</p>

<script type="math/tex; mode=display">% <![CDATA[
X = \begin{bmatrix}
	1.4 & -1 & 0.4 & 1 \\
	0.4 & -1 & 0.1 & 1 \\
	5.4 & -1 & 4 & 1 \\
	1.5 & -1 & 1 & 1 \\
	1.8 & 1 & 1 & 1
\end{bmatrix} %]]></script>

<p>В матрице весов <script type="math/tex">W_1</script> появится новая строка <script type="math/tex">[W_{41}^1\quad W_{42}^1\quad W_{43}^1]</script>, так как добавление нового столбца к входам приводит к созданию новых связей. Это строка состоит из смещений, мы инициализируем их значениями <script type="math/tex">0.1</script> (они должны быть установлены в значения нуля или значения близкие к нулю).</p>

<p>And our <script type="math/tex">W_1</script> matrix has a new row <script type="math/tex">[W_{41}^1\quad W_{42}^1\quad W_{43}^1]</script>, because adding 1 to our input created new links. This row is the biases, we init them at 0.1 so that we will see the differences with the previous values (they should be initialised at 0 or around 0).</p>

<script type="math/tex; mode=display">% <![CDATA[
W^1 = \begin{bmatrix}
	0.01 & 0.05 & 0.07 \\
	0.20 & 0.041 & 0.11 \\
	0.04 & 0.56 & 0.13 \\
	0.1 & 0.1 & 0.1
\end{bmatrix} %]]></script>

<p>Теперь повторим все вычисления также как мы делали это прежде.</p>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(2)} = \begin{bmatrix}
	1.4 & -1 & 0.4 & 1\\
	0.4 & -1 & 0.1 & 1 \\
	5.4 & -1 & 4 & 1 \\
	1.5 & -1 & 1 & 1 \\
	1.8 & 1 & 1 & 1
\end{bmatrix}.\begin{bmatrix}
	0.01 & 0.05 & 0.07 \\
	0.20 & 0.041 & 0.11 \\
	0.04 & 0.56 & 0.13 \\
	0.1 & 0.1 & 0.1
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(2)} = \begin{bmatrix}
	-0.07 & 0.353 & 0.14 \\
	-0.092 & 0.135 & 0.031 \\
	0.114 & 2.569 & 0.888 \\
	-0.045 & 0.694 & 0.225 \\
	0.358 & 0.791 & 0.466
\end{bmatrix} %]]></script>

<p>Если вы сравните текущие значения <script type="math/tex">Z^{(2)}</script> со значениями полученными до добавления смещений, то заметите, что все значения в <script type="math/tex">Z^{(2)}</script> изменились на <script type="math/tex">+0.1</script>. Теперь применим функцию активации:</p>

<script type="math/tex; mode=display">a^{(2)} = tanh(Z^{(2)})</script>

<script type="math/tex; mode=display">% <![CDATA[
a^{(2)} = \begin{bmatrix}
	-0.06988589 & 0.33903341 & 0.13909245 \\
	−0.09174131 & 0.13418581 & 0.03099007 \\
	0.11350871 & 0.98832966 & 0.71040449 \\
	−0.04496965 & 0.60054553 & 0.22127847 \\
	0.34345116 & 0.65897516 & 0.43496173
\end{bmatrix} %]]></script>

<p>Мы также добавим смещение к первому скрытому слою. Также как и в случае с матрицей признаков это означает добавление 1 как четвертого нейрона к <script type="math/tex">a^{(2)}</script>. В качестве напоминания, каждая строка содержит данные об одном автомобиле:</p>

<p>We also add a bias to our first hidden layer. As we did with the inputs we must add 1 as a fourth neuron to a(2). As a reminder, each row contains data for one car.</p>

<script type="math/tex; mode=display">% <![CDATA[
a^{(2)} = \begin{bmatrix}
	-0.06988589 & 0.33903341 & 0.13909245 & 1 \\
	−0.09174131 & 0.13418581 & 0.03099007 & 1 \\
	0.11350871 & 0.98832966 & 0.71040449 & 1 \\
	−0.04496965 & 0.60054553 & 0.22127847 & 1 \\
	0.34345116 & 0.65897516 & 0.43496173 & 1
\end{bmatrix} %]]></script>

<p>После добавления смещения к <script type="math/tex">a^{(2)}</script> будут образованы новые связи между вторым и третьим слоями. Аналогично <script type="math/tex">W_1</script>, мы добавим новую строку в <script type="math/tex">W_2</script> со значениями <script type="math/tex">0.1</script>.</p>

<p>As we added a 1 neuron to a(2) new links are created between the layer 2 and 3, as for W1, W2 will gain a row of biases that we init at 0.1.</p>

<script type="math/tex; mode=display">% <![CDATA[
W^2 = \begin{bmatrix}
	0.04 & 0.78 \\
	0.40 & 0.45 \\
	0.65 & 0.23 \\
	0.1 & 0.1
\end{bmatrix} %]]></script>

<p>We do the same calculations as before:</p>

<script type="math/tex; mode=display">Z^{(3)} = a^{(2)} . W^2</script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(3)} = \begin{bmatrix}
	-0.06988589 & 0.33903341 & 0.13909245 & 1 \\
	−0.09174131 & 0.13418581 & 0.03099007 & 1 \\
	0.11350871 & 0.98832966 & 0.71040449 & 1 \\
	−0.04496965 & 0.60054553 & 0.22127847 & 1 \\
	0.34345116 & 0.65897516 & 0.43496173 & 1
\end{bmatrix}.\begin{bmatrix}
	0.04 & 0.78 \\
	0.40 & 0.45 \\
	0.65 & 0.23 \\
	0.1 & 0.1
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(3)} = \begin{bmatrix}
	0.32322802 & 0.2300453 \\
	0.17014822 & 0.09595311 \\
	0.96163513 & 0.79667817 \\
	0.48225043 & 0.38606321 \\
	0.66005324 & 0.76447193
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">a^{(3)} = tanh(Z^{(3)})</script>

<script type="math/tex; mode=display">% <![CDATA[
a^{(3)} = \begin{bmatrix}
	0.31242279 & 0.22607134 \\
	0.16852506 & 0.09565971 \\
	0.74500533 & 0.66217559 \\
	0.44804409 & 0.3679614 \\
	0.57839884 & 0.64370347
\end{bmatrix} %]]></script>

<p>Finally we also add a bias neuron to a(3), as before new links are created between the layer 3 and 4, as for W2, W3 will gain a row of biases that we init at 0.1</p>

<script type="math/tex; mode=display">Z^{(4)} = a^{(3)}.W^3</script>

<script type="math/tex; mode=display">% <![CDATA[
Z^{(4)} = \begin{bmatrix}
	0.31242279 & 0.22607134 & 1 \\
	0.16852506 & 0.09565971 & 1 \\
	0.74500533 & 0.66217559 & 1 \\
	0.44804409 & 0.3679614 & 1 \\
	0.57839884 & 0.64370347 & 1
\end{bmatrix}.\begin{bmatrix}
	0.04 \\
	0.41 \\
	0.1
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">Z^{(4)} = \begin{bmatrix}
	0.20518616 \\
	0.14596148 \\
	0.4012922 \\
	0.26878594 \\
	0.38705438
\end{bmatrix}</script>

<p>Затем мы применяем функцию активации:</p>

<script type="math/tex; mode=display">a^{(4)} = tanh(Z^{(4)}) = \begin{bmatrix}
	0.2023543 \\
	0.14493368 \\
	0.38105408 \\
	0.26249479 \\
	0.36881806
\end{bmatrix}</script>

<p>Значения полученные в выходном слое нашей сети являются прогнозами. Мы запишем их в матрицу <script type="math/tex">\hat{y} = a^{(4)}</script>. <script type="math/tex">\hat{y}</script> является спрогнозированной ценой автомобиля, в то время как <script type="math/tex">y</script> (без крышки) является истинной ценой автомобиля. Например, наша сеть «думает», что стоимость первого автомобиля меньше, чем стоимость пятого.</p>

<p>Добавление смещений</p>

<p>Adding the biases is really simple (just add a neuron 1) and will greatly improve our results. The whole calculation that we did, from X to a(4) is called forward propagation. This is how we will infer the price of a car in the future. We will take the car attributes, make the same calculations and get a price in the a(4) matrix.</p>

<p>В настоящий момент, полученные нами результаты не так хороши как хотелось бы, так как мы выбрали случайные значения для матрицы весов. Мы будем обучать нашу сеть шаг за шагом, изменяя значения весов до тех пор пока не начнем получать хорошие прогнозы.</p>

<p>Right now our results are pretty bad because we randomly initialised our weights. We will train our network step by step in order to tweak the weights until it outputs good predictions.</p>

<p>В нашем исходном наборе данных мы имеем дело с атрибитуами автомобиля и его ценой. Признаки (атрибуты) первого автомобиля и смещения были
<script type="math/tex">X = [1.4\quad −1\quad 0.41]</script>, а его цена <script type="math/tex">y = 0.45</script>. Наша сеть дала прогноз <script type="math/tex">\hat{y}=0.2023543</script>. Посчитав <script type="math/tex">y−\hat{y}</script> становится очевидным, что мы ошиблись на <script type="math/tex">0.25</script>. Это называется ошибкой (невязкой, cost) - как сильно ошибается наша сеть в своем прогнозе относительно истинного значения цены.</p>

<p>In our original dataset we have the car attributes and the car price. The features (attributes) of the first car with the bias was <script type="math/tex">X = [1.4\quad −1\quad 0.41]</script> and its price was y=0.45. Our network output was <script type="math/tex">\hat{y}=0.2023543</script> given in <script type="math/tex">a_{1}^{(4)}</script>. We clearly see that we are missing around 0.25 by doing <script type="math/tex">y−\hat{y}</script>. This is called the cost, how bad our network predicted the price compared to the actual price. Actually we will define a cost function in order to mesure how bad our predictions are.</p>

<script type="math/tex; mode=display">J(W) = \frac{1}{2}(y - \hat{y})^2</script>

<p>Так мы можем посчитать значение ошибки для одного наблюдения. Например, для нашего первого наблюдения истинное значение цены <script type="math/tex">0.45</script>, прогноз сети <script type="math/tex">0.2023543</script> и, используя приведенную формулу, мы получаем значение ошибки <script type="math/tex">J(W) = \frac{1}{2}(0.45−0.2023543)^2 = 0.031</script>.</p>

<p>Если повторить эти вычисления для всех наблюдений и посчитать сумму ошибок, то получим следующую формулу:</p>

<script type="math/tex; mode=display">J(W) = \sum^{n}_{1}\frac{1}{2}(y - \hat{y})^2</script>

<p>Где <script type="math/tex">n</script> это число наблюдений (автомобилей). Мы считаем квадрат ошибки не только для того, чтобы получить асболютное значение ошибки и, как следствие, ошибки с разным знаком не компенсировали друг друга, но также по той причине, что квадратичная функция <script type="math/tex">x^2</script> является выпуклой (convex), а это означает, что у функции только один минимум. Откуда появился множитель <script type="math/tex">\frac{1}{2}</script> будет объяснено далее.</p>

<h3 id="gradient-descent">Gradient descent</h3>

<p>Функция <script type="math/tex">J(W)</script> показывает величину ошибки работы нашей сети относительно входных значений <script type="math/tex">X</script> и значений весов. Если мы заменим <script type="math/tex">\hat{y}</script> соответствующим выражением, то получим:</p>

<script type="math/tex; mode=display">J(W)=\sum^{n}_{1}\frac{1}{2}(y−tanh⁡(tanh⁡(tanh⁡(X.W_1).W_2).W_3))^2</script>

<p>The function J(W) gives us the error of our network regarding our inputs X and the weights of our network. If we replace y^ by its calculations, our function is:</p>

<script type="math/tex; mode=display">J(W)=\sum^{n}_{1}\frac{1}{2}(y−tanh⁡(tanh⁡(tanh⁡(X.W_1).W_2).W_3))^2</script>

<p><script type="math/tex">J(W)</script> является функцией, которая даем нам . Чем меньше ее значение, тем лучшие прогнозы выдает наша сеть. Наша цель минимизировать функицю <script type="math/tex">J(W)</script>, например, найти ее минимум. Это задача оптимизации. Мы не можем изменять значения в наблюдениях <script type="math/tex">X</script>, поэтому мы будем минимизировать <script type="math/tex">J(W)</script> изменяя значения весов. Мы будем использовать метод градиентного спуска (batch gradient descent) (with a non convex cost function it is better to use the stochastic gradient descent). Хоть мы и выбрали метод градиентного спуска в качестве алгоритма оптимизации, но возможны и другие подходы. Давайте разберемся с тем, что такое градиент.</p>

<p><script type="math/tex">J(W)</script> is a function that gives us the cost regarding our examples (the cars) and the weights (W1, W2 and W3). The minimum the cost is, the better our network predicts. Our goal is to minimize the function J(W), i.e: find its minimum. This is an optimization problem. We can’t touch our examples X so we will minimize our function J(W) by tweaking the weights. We will use the batch gradient descent algorithm (with a non convex cost function it is better to use the stochastic gradient descent). We choose the gradient descent as the optimization algorithm but other alternatives could be used. Let’s see what a gradient is.</p>

<p>В математике фунция это правило указывающее как</p>

<p>In mathematics, a function is a rule explaining how to process an input to give an output. The input is noted as x and the output as y, the function is generally written as <script type="math/tex">y = f(x)</script>. It is possible to have multiple inputs and outputs, multiple inputs is common and looks like <script type="math/tex">z=f(x,y)</script>, multiple outputs is a vector valued function that produces a vector instead of only y.</p>

<p>Строго говоря входные значения называются независимыми переменными, а выходные значения - зависимыми.</p>

<p>Strictly speaking the inputs are called independent variables and the outputs dependent variables. The function explains how the dependent variables depend on the independent variables.</p>

<p>Производная функции играет ключевую роль в машинном обучении и используется среди прочих в методе градиентного спуска.</p>

<p>The derivative of a function is a key tool in machine learning, it is leveraged among others by the gradient descent algorithm. The derivative measures how a change in the independent variables impact the dependent variables (how changing x impacts y). The process of finding the derivative is called differentiation.</p>

<p>There are two cases useful to us.</p>

<p>The first case is when there is only one independent variable and one dependent variable (y=f(x) where <script type="math/tex">x \in R</script> and <script type="math/tex">y \in R</script>). In that case the derivative of a function at a given input is the slope of the tangent line to the graph of the function at the given input. It means that at the given input, the function is well-approximated by a straight line, and the derivative is the slope of this straight line. Let’s take an example. For instance if we take the sigmoïd function:</p>

<script type="math/tex; mode=display">\sigma(x) = \frac{1}{1+e^{-x}}</script>

<p>The derivative of this function is:</p>

<script type="math/tex; mode=display">\frac{e^x}{(e^x + 1)^2}</script>

<p>You can compute the derivative detail here. Let’s use this derivative to calculate the slope of the tangent at x=2, we have:</p>

<script type="math/tex; mode=display">\frac{e^2}{(e^2 + 1)^2} \approx 0.105</script>

<p>If we draw the sigmoid function with its tangent at x=2 we see that the slope of the tangent is <script type="math/tex">\approx 0.105</script>:</p>

<p><img src="/assets/images/notes-on-nn/DNN-FUNC5.png" alt="" /></p>

<p>Our function does not looks like the sigmoid function because we used the same scale for the x and y, it is easier to see that the slope of the tangent, the blue line, is indeed <script type="math/tex">\approx 0.105</script>.</p>

<p>The tangent is the best linear approximation of a function at a given value, it shows how the independent variable impacts the dependent variable (small or big slope).</p>

<p>The second case is when there are several independent variables (y=f(x) where <script type="math/tex">x \in R^n</script> and <script type="math/tex">y \in R</script>). As the function takes as input several variables, we will now compute the partial derivative of the function with respect to each input variable.</p>

<p>The partial derivative of a function w.r.t (with respect to) one of the input variable is the derivative of the function where others variables held constant. It indicates the rate of change of a function with respect to that variable surrounding an infinitesimally small region near a particular point.</p>

<p>If we take for example, <script type="math/tex">z=x^2+y^3</script>, we have two inputs x and y so the derivative of the function will be a vector containing two partial derivatives:</p>

<script type="math/tex; mode=display">F = \begin{bmatrix}
	\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}
\end{bmatrix}</script>

<p>To calculate the partial derivative <script type="math/tex">\frac{\partial f}{\partial x}</script> we held <script type="math/tex">y^3</script> as a constant so we have:</p>

<script type="math/tex; mode=display">\frac{\partial f}{\partial x} = 2x + 0 = 2x</script>

<p>To calculate the partial derivative <script type="math/tex">\frac{\partial f}{\partial y}</script> we held <script type="math/tex">x^2</script> as a constant so we have:</p>

<script type="math/tex; mode=display">\frac{\partial f}{\partial y} = 3y^2 + 0 = 3y^2</script>

<p>So the derivative of our initial function is:</p>

<script type="math/tex; mode=display">F = \begin{bmatrix}
	2x, 3y^2
\end{bmatrix}</script>

<p>This vector of partial derivatives is the gradient. It represents the slope of the tangent of the graph of the function, it means that the gradient points in the direction of the greatest rate of increase of the function and its magnitude is the slope of the graph in that direction.</p>

<p>For instance, for the previous function, if we are at x=4 and y=2, the corresponding gradient is (8,12) (we are using (2x,3y2)). It means that the function increases more in the direction of y than x. Using the two informations, it gives us a vector (a direction) for which Z will increase the most.</p>

<p>If we draw the previous function in a 3D space, it looks like the following:</p>

<p><img src="/assets/images/notes-on-nn/grad_desc3D.png" alt="" /></p>

<p>If we forget the z (because we can’t tune its value) we have a 2D surface on which we can move on the x and y axis, it is like watching the previous 3D drawing from above, the z axis does not appear.</p>

<p>We can place our original point (x=4 and y=2) in red, its derivative (8,12) in blue and draw an arrow between them (orange).</p>

<p><img src="/assets/images/notes-on-nn/grad_desc2D.png" alt="" /></p>

<p>The orange arrow is the gradient, it gives us the direction of the steepest increase of z and the length of the arrow gives us how z changes, a long arrow means a big slope. If it is always unclear, here is a 5 minutes video that can help you understand.</p>

<p>Gradient descent is an optimization algorithm, it allows to find a local minimum of a function.</p>

<p>The algorithm comes from the observation that if one goes in the direction of the negative gradient of a function, the function decreases faster.</p>

<p>As we saw previously, the gradient gives us the direction of the maximum increase of the function, we use the negation of this gradient to update the coordinates of our position in the space.</p>

<p>By doing it repeatedly we are sure to find a local minimum of the function.</p>

<p>Let’s say that our function is <script type="math/tex">z=x^2+y^3</script>, its gradient is <script type="math/tex">F=[2x,3y^2]</script> so if we are at <script type="math/tex">x=4</script> and <script type="math/tex">y=2</script>, the corresponding gradient is <script type="math/tex">(8,12)</script>.</p>

<p>The basic idea is to substract this gradient from our original coordinates, but directly substracting the gradient would produce a big jump from our original coordinates. For our example we are at (4,2), if we directly substract the gradient, we will be at (4−8,2−12)=(−4,−10). What a big jump. So before to substract it we multiply it by a coefficient so that its value will be reduced. We have (4−0.01∗8,2−0.01∗12)=(3.92,1.88). We did a small move but at least we will not miss the minima.</p>

<p>This coefficient 0.01 is called the learning rate, how much the gradient will impact our current position. A big learning rate means bigger steps but we could jump over the minimum of the function. A small learning rate means a little but precise step and more steps needed to find the minimum. This value must be small and the perfect value is determined by a try/fail process.</p>

<p>So if we summarize, we are at a point in our space and we want to find the minimum of a function. If we find the minimum we will have found the weights that give us the lowest error. So for the given coordinates, we compute the gradient, we multiply the gradient by a tiny coefficient and then we substract this updated gradient from our coordinates. This gives us our new coordinates and we start again.</p>

<p>This repeated process is the gradient descent algorithm. If the function that we are trying to minimize is convex, all local minimas are also global minimas so gradient descent descent will give us the global solution (but it can take an eternity). A convex cost function is not mandatory.</p>

<p>If we complete the image showing several iterations from wikipedia, we have:</p>

<p><img src="/assets/images/notes-on-nn/grad_desc_steps.png" alt="" /></p>

<p>The red cross is our minima, the red arrow is the negative gradient that we substract from our coordinates and the orange arrows are the actual gradients. As you can see the red arrow is smaller than the orange arrow because the gradient has been multiplied by the learning rate (so reduced). The green dots are the new coordinates produced after each iteration. If <script type="math/tex">X_0</script> is our original point, we see four iterations on the picture.</p>

<h3 id="backpropagation">Backpropagation</h3>

<p>Our goal is therefore to find the gradients of our function J(W) and use them to update the weights of our network. Our cost function computes three inputs that are the network weights. We have to find the partial derivatives (gradients) with regards to its weights.</p>

<script type="math/tex; mode=display">\nabla (J(W)) = [\frac{\partial J(W)}{\partial W_1}, \frac{\partial J(W)}{\partial W_2}, \frac{\partial J(W)}{\partial W_3}]</script>

<p>Then we will update the weights using the gradients, for instance W1 will be updated using the following rule:</p>

<script type="math/tex; mode=display">W_1 = W_1 - \alpha \frac{1}{n}\frac{\partial J(W)}{\partial W_1}</script>

<p>Where <script type="math/tex">\alpha</script> is our learning rate, we divide by n, which is the number of inputs (our cars) because the gradients for each car will be summed and we are using the averaged gradient to update our weights W1.</p>

<p>We could directly apply the backpropagation algorithm to find the gradients of J(W) but we will compute the derivative of our cost function to get a better understanding of the algorithm.</p>

<p>As a reminder:</p>

<script type="math/tex; mode=display">J(W)=\sum^{n}_{1}\frac{1}{2}(y−tanh⁡(tanh⁡(tanh⁡(X.W_1).W_2).W_3))^2</script>

<p>Our cost function is a composition of several functions, you can see a tanh into a tanh into a tanh. To derive it we will use the chain rule. It is a formula for computing the derivative of the composition of two or more functions.</p>

<p>The usual formula is:</p>

<script type="math/tex; mode=display">(f \circ g)' = (f' \circ g).g'</script>

<p>For instance if we take the function <script type="math/tex">f(x)=(2x^2+8)^3</script> we see a composition. The result of the first function <script type="math/tex">g(x)=2x^2+8</script> is used by the second function <script type="math/tex">f(g(x))=(g(x))^3</script>. The derivative of <script type="math/tex">g(x)</script> is <script type="math/tex">g'(x)=4x</script> and the derivative of <script type="math/tex">f(g(x))</script> is <script type="math/tex">f'(g(x))=3g(x)^2</script>. We apply the above formula:</p>

<script type="math/tex; mode=display">f'(x) = f'(g(x)).g'(x)=3(2x^2+8)^2 \cdot 4x</script>

<p>The chain rule can also be written in the following way:</p>

<script type="math/tex; mode=display">\frac{\partial z}{\partial x} = \frac{\partial z}{\partial y} \cdot \frac{\partial y}{\partial x}</script>

<p>Meaning that if y depends on x and z depends on y, z also depends on x. If we use our previous example. We want <script type="math/tex">\frac{\partial f}{\partial x}</script>. We know that f depends on g and g depends on x because <script type="math/tex">f(g(x))=g(x)^3</script> and <script type="math/tex">g(x)=2x^2+8</script> so we can write:</p>

<script type="math/tex; mode=display">\frac{\partial f}{\partial x} = \frac{\partial f}{\partial g} \cdot \frac{\partial g}{\partial x}</script>

<p>Then we compute the derivative:</p>

<script type="math/tex; mode=display">\frac{\partial f}{\partial g} = 3g(x)^2</script>

<script type="math/tex; mode=display">\frac{\partial g}{\partial x} = 4x</script>

<script type="math/tex; mode=display">\frac{\partial f}{\partial x} = 3(2x^2 + 8)^2 \cdot 4x</script>

<p>We will use the same way to compute the gradients of our cost function. There is a sum in our cost function, meaning that we have to add all together the cost of each input (our cars) in order to obtain the overall cost. We will forget it for now and talk about it later, the sum rule allows us to ignore it for now. The derivative of the sums equals the sum of the derivatives. At the end, once we have the derivative for one example we will just sum up the derivatives of all examples. So we have:</p>

<script type="math/tex; mode=display">J(W) = \frac{1}{2}(y - \hat{y})^2</script>

<p>And we have to find:</p>

<script type="math/tex; mode=display">\nabla (J(W)) = [\frac{\partial J(W)}{\partial W_1}, \frac{\partial J(W)}{\partial W_2}, \frac{\partial J(W)}{\partial W_3}]</script>

<p>We begin from the output of our network, so let’s find <script type="math/tex">\frac{\partial J(W)}{\partial W_3}</script> first. We want the derivative of J(W) with regards to W3, it means that other variables, meaning W1 and W2 are held constants.</p>

<p>We have:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = \frac{1}{2}(y - \hat{y})^2</script>

<p>We can see a first composition. <script type="math/tex">J(W)=\frac{1}{2}(g(x))^2</script> where <script type="math/tex">g(x)=y−\hat{y}</script> so we have:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = \frac{\partial J(W)}{\partial g} \cdot \frac{\partial g}{\partial W_3}</script>

<p>Using the power rule, we have:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial g} = 2 \times \frac{1}{2}(g(x)) = g(x)</script>

<p>Thats why we put <script type="math/tex">\frac{1}{2}</script> in our cost function, so that when differentiating things go smoothly and the term <script type="math/tex">2 \times \frac{1}{2}</script> disappear. So:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = g(x) \cdot \frac{\partial g}{\partial W_3} = (y - \hat{y}) \cdot \frac{\partial g}{\partial W_3}</script>

<p>Now let’s find the <script type="math/tex">\frac{\partial g}{\partial W_3}</script> term, as a reminder <script type="math/tex">g(x)=y−\hat{y}</script>, we know that y is a constant that does not depend on <script type="math/tex">W_3</script> whereas <script type="math/tex">\hat{y}</script> does depend on it. We have:</p>

<script type="math/tex; mode=display">\frac{\partial g}{\partial W_3} = 0 - \frac{\partial \hat{y}}{\partial W_3}</script>

<p>And:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = (y - \hat{y}) \cdot -\frac{\partial \hat{y}}{\partial W_3}</script>

<p>As we said before, <script type="math/tex">\hat{y}</script> is our predictions, meaning the output of our network, meaning <script type="math/tex">a^{(4)}</script>. We know that <script type="math/tex">\hat{y} = a^{(4)} = tanh(Z^{(4)})</script> so our <script type="math/tex">\hat{y}</script> depends on <script type="math/tex">Z^{(4)}</script> and <script type="math/tex">Z^{(4)}</script> depends on <script type="math/tex">W_3</script>. So we can write:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = (y - \hat{y}) \cdot -\frac{\partial \hat{y}}{\partial Z^{(4)}} \cdot \frac{\partial Z^{(4)}}{\partial W_3}</script>

<p>We can find <script type="math/tex">\frac{\partial \hat{y}}{\partial Z^{(4)}}</script> directly, we have: <script type="math/tex">\hat{y}=tanh(Z^{(4)})</script> so our derivative with regards to Z(4) is the following:</p>

<script type="math/tex; mode=display">\frac{\partial \hat{y}}{\partial Z^{(4)}} = tanh'(Z^{(4)}) = 1 - tanh(Z^{(4)})^2</script>

<p>We can replace its value in our initial formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = (y - \hat{y}) \cdot - (1 - tanh(Z^{(4)})^2) \cdot \frac{\partial Z^{(4)}}{\partial W_3}</script>

<p>Now we have one final term to compute <script type="math/tex">\frac{\partial Z^{(4)}}{\partial W_3}</script> and we know that Z(4)=a(3)⋅W3. Finally Z(4) depends on W3 directly so no more chain rule needed for this first gradient. We keep a(3) as a constant and W3 becomes one because we are differentiating with regard to W3. We have:</p>

<script type="math/tex; mode=display">\frac{\partial Z^{(4)}}{\partial W_3} = a^{(3)} \times 1 = a^{(3)}</script>

<p>We can replace it in our initial formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = (y - \hat{y}) \cdot - (1 - tanh(Z^{(4)})^2) \cdot a^{(3)}</script>

<p>We found our first gradient! We will use it during the training process to update our weights <script type="math/tex">W_3</script>.</p>

<p>We will introduce <script type="math/tex">\delta^{(4)}</script> equals to:</p>

<script type="math/tex; mode=display">\delta^{(4)} = (y - \hat{y}) \cdot - (1 - tanh(Z^{(4)})^2)</script>

<p>So our previous gradient is in fact:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = \delta^{(4)} \cdot a^{(3)}</script>

<p>Now we need our second gradient, <script type="math/tex">\frac{\partial J(W)}{\partial W_2}</script>, we will use the same steps as before for the beginning. We begin from:</p>

<script type="math/tex; mode=display">J(W) = \frac{1}{2}(y-\hat{y})^2</script>

<p>Using the exact same steps as for W3 we will arrive at:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = (y-\hat{y}) \cdot - (1-\tanh(Z^{(4)})^2) \cdot \frac{\partial Z^{(4)}}{\partial W_2}</script>

<p>You can see above that we have the same term as before, that’s why we introduced <script type="math/tex">\delta^{(4)}</script>, we can replace it in our formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = \delta^{(4)} \cdot \frac{\partial Z^{(4)}}{\partial W_2}</script>

<p>Before we were searching the derivative of Z(4) with regards to W3 so the derivative was a(3)×1, as a reminder Z(4)=a(3)⋅W3 but this time we are searching the derivative with regards to W2. W3 does not depend on W2 so it becomes a constant, meanwhile a(3) depends on W2 so we have to find its derivative with regards to W2. This gives us:</p>

<script type="math/tex; mode=display">\frac{\partial Z^{(4)}}{\partial W_2} = W_3 \cdot \frac{\partial a^{(3)}}{\partial W_2}</script>

<p>We can replace it in our original formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = \delta^{(4)} \cdot W_3 \cdot \frac{\partial a^{(3)}}{\partial W_2}</script>

<p>Now we have to compute ∂a(3)∂W2, we know that a(3) depends on z(3) (because a(3)=tanh(z(3))) which itself depends on W2 (because z(3)=a(2)⋅W2). Using the chain rule we can write:</p>

<script type="math/tex; mode=display">\frac{\partial a^{(3)}}{\partial W_2} = \frac{\partial a^{(3)}}{\partial z^{(3)}} \cdot \frac{\partial z^{(3)}}{\partial W_2}</script>

<p>We can replace it in our original formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = \delta^{(4)} \cdot W_3 \cdot \frac{\partial a^{(3)}}{\partial z^{(3)}} \cdot \frac{\partial z^{(3)}}{\partial W_2}</script>

<p>We differentiate ∂a(3)∂z(3), we have:</p>

<script type="math/tex; mode=display">\frac{\partial a^{(3)}}{\partial z^{(3)}} = tanh'(z^{(3)}) = 1-\tanh(Z^{(3)})^2</script>

<p>We can replace it in our original formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = \delta^{(4)} \cdot W_3 \cdot 1-\tanh(Z^{(3)})^2 \cdot \frac{\partial z^{(3)}}{\partial W_2}</script>

<p>And we differentiate the last missing term ∂z(3)∂W2:</p>

<script type="math/tex; mode=display">\frac{\partial z^{(3)}}{\partial W_2} = a^{(2)} \cdot 1 = a^{(2)}</script>

<p>We can replace it in our original formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = \delta^{(4)} \cdot W_3 \cdot 1-\tanh(Z^{(3)})^2 \cdot a^{(2)}</script>

<p>We found the second gradient of our function J(W). As you can see, the more you go toward the beginning of the network, the more the differentiation will be long. That’s why we introduced the δ(l) terms where l is the layer number. So that we don’t have to differentiate again the first part of the function but directly use δ(l). For the second gradient we introduce:</p>

<script type="math/tex; mode=display">\delta^{(3)} = \delta^{(4)} \cdot W_3 \cdot 1-\tanh(Z^{(3)})^2</script>

<p>We now have to find our last gradient ∂J(W)∂W1, we will use the same steps as before for the beginning. We begin from:</p>

<script type="math/tex; mode=display">J(W) = \frac{1}{2}(y-\hat{y})^2</script>

<p>Using the exact same steps as for W2 we will arrive at:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(4)} \cdot W_3 \cdot 1-\tanh(Z^{(3)})^2 \cdot \frac{\partial z^{(3)}}{\partial W_1}</script>

<p>As we introduced δ(3) we can use it:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(3)} \cdot \frac{\partial z^{(3)}}{\partial W_1}</script>

<p>Before we were searching the derivative of z(3) with regards to W2 and so the derivative was equal to a(2). As a reminder z(3)=a(2)⋅W2. This time we are searching the derivative of z(3) with regards to W1 and so W2 is only a constant, we have:</p>

<script type="math/tex; mode=display">\frac{\partial z^{(3)}}{\partial W_1} = W_2 \cdot \frac{\partial a^{(2)}}{\partial W_1}</script>

<p>We can replace it in our original formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(3)} \cdot W_2 \cdot \frac{\partial a^{(2)}}{\partial W_1}</script>

<p>We now have to find the derivative of ∂a(2)∂W1, we know that a(2) depends on z(2) which itself depends on W1. As before we can use the chain rule here. We have:</p>

<script type="math/tex; mode=display">\frac{\partial a^{(2)}}{\partial W_1} = \frac{\partial a^{(2)}}{\partial z^{(2)}} \cdot \frac{\partial z^{(2)}}{\partial W_1}</script>

<p>Where:</p>

<script type="math/tex; mode=display">\frac{\partial a^{(2)}}{\partial z^{(2)}} = tanh'(z^{(2)}) = 1-\tanh(Z^{(2)})^2</script>

<p>We replace it in our original formula:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(3)} \cdot W_2 \cdot 1-\tanh(Z^{(2)})^2 \cdot \frac{\partial z^{(2)}}{\partial W_1}</script>

<p>We have one last term to differentiate, if you remember z(2)=X⋅W1 as we differentiate with regards to W1 we have:</p>

<script type="math/tex; mode=display">\frac{\partial z^{(2)}}{\partial W_1} = X \cdot W_1 = X</script>

<p>So our last gradient is:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(3)} \cdot W_2 \cdot 1-\tanh(Z^{(2)})^2 \cdot X</script>

<p>We also introduce the term δ(2), we have:</p>

<script type="math/tex; mode=display">\delta^{(2)} = \delta^{(3)} \cdot W_2 \cdot 1-\tanh(Z^{(2)})^2</script>

<p>And:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(2)} \cdot X</script>

<p>Here we are, we found the gradient of J(W) with regards to its weights. As a reminder we found:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = \delta^{(2)} \cdot X</script>

<script type="math/tex; mode=display">\delta^{(2)} = \delta^{(3)} \cdot W_2 \cdot 1-\tanh(Z^{(2)})^2</script>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = \delta^{(3)} \cdot a^{(2)}</script>

<script type="math/tex; mode=display">\delta^{(3)} = \delta^{(4)} \cdot W_3 \cdot 1-\tanh(Z^{(3)})^2</script>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = \delta^{(4)} \cdot a^{(3)}</script>

<script type="math/tex; mode=display">\delta^{(4)} = (y-\hat{y}) \cdot - (1-\tanh(Z^{(4)})^2)</script>

<p>If you remember, each gradient will be used to update a weight matrix during one gradient descent iteration. This means that our gradients should have the same size as the weights matrix that will use it. For instance W3 is a 2×1 matrix so ∂J(W)∂W3 must be a 2×1 matrix.</p>

<p>We will detail the dimensions of the matrices used to calculate our gradients so that it appears clearly that the gradients are summed up. It will also be useful to know when were are using element wise or matrix multiplication. Let’s say that we have five cars, for ∂J(W)∂W3 we found:</p>

<p><img src="/assets/images/notes-on-nn/DW3-DIMENSIONS.png" alt="" /></p>

<p>The <script type="math/tex">\odot</script> means an element wise multiplication, the ⋅ means a matrix multiplication. From now on we will distinguish between the two. Our δ(4) term has a dimension of 5×1 and a(3) has a dimension of 5×2. As we want the same dimension as W3 meaning 2×1 there is only one way to achieve that:</p>

<p><img src="/assets/images/notes-on-nn/DW3-DIMENSIONS-STEP2.png" alt="" /></p>

<p>By inverting δ(4) and a(3) and using the transpose of a(3) we are able to get the desired result. a(3) contains the neurons values of the the third layer, two for each car and δ(4) contains the error for each car. By doing the matrix multiplication we are actually summing the neurons of all the cars where each car neuron value is multiplied by the error for the given car. If you remember we removed the sum from our cost function, this step takes care of the summation of the errors using the matrix multiplication.</p>

<p><img src="/assets/images/notes-on-nn/DW3-DIMENSIONS-STEP3.png" alt="" /></p>

<p>So we modify our third gradient so that the summation is handled and the dimension of the matrices are compatible (the little <script type="math/tex">\intercal</script> means transpose):</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = a^{(3)\intercal} \cdot \delta^{(4)}</script>

<script type="math/tex; mode=display">\delta^{(4)} = (y-\hat{y}) \odot - (1-\tanh(Z^{(4)})^2)</script>

<p>Our δ(l) will always have the same size as a(l) because it mesures how much a neuron is responsible for any error in our output. This remark is important because during the forward propagation we added bias units to each of our layer, having the effect of increasing the a(l) dimension by one column. δ(l) will also contain the error of the bias units. These bias units are not linked to the previous layers so when we backpropagate our δ(l) into our (l−1) layer we will have to remove the bias error. We will detail the dimensions of the matrices, we also have five cars. Using the same reasoning as before (transpose + inversion) we find that:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = a^{(2)\intercal} \cdot \delta^{(3)}</script>

<script type="math/tex; mode=display">\delta^{(3)} = (\delta^{(4)} \cdot W_3^{\intercal}) \odot 1-\tanh(Z^{(3)})^2</script>

<p>As you can see the order of the calculations follows the output toward input flow. We have:</p>

<p><img src="/assets/images/notes-on-nn/DW2-DIMENSIONS-2.png" alt="" /></p>

<p>The third element of W3 is the bias value, as we also multiply it with δ(4) the result of our product δ(4)⋅W3⊺ is of size 5×3 whereas Z(3) is of size 5×2. To allow a smooth element wise multiplication we add a column of 1 to Z(3). The result is unchanged and δ(3) is of size 5×3 like a(3).</p>

<p>Nonetheless the bias is not linked to the previous layer, this means that when backpropagating the error δ(3) we must remove the part about the bias in the error matrix. We have:</p>

<p><img src="/assets/images/notes-on-nn/DW2-DIMENSIONS-3.png" alt="" /></p>

<p>The greyed circles are removed from the δ(3) before the multiplication, ∂J(W)∂W2 has the same size as W2.</p>

<p>We use the same tricks for ∂J(W)∂W1.</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = X^{\intercal} \cdot \delta^{(2)}</script>

<script type="math/tex; mode=display">\delta^{(2)} = (\delta^{(3)} \cdot W_2^{\intercal}) \odot 1-\tanh(Z^{(2)})^2</script>

<p>We have:</p>

<p><img src="/assets/images/notes-on-nn/DW1-DIMENSION.png" alt="" /></p>

<p>And:</p>

<p><img src="/assets/images/notes-on-nn/DW1-DIMENSION-STEP-2.png" alt="" /></p>

<p><script type="math/tex">\frac{\partial J(W)}{\partial W_1}</script> has the same size as W1.</p>

<p>This may seem difficult but using the dimension analysis and knowing when to remove the bias error and add a 1 column, there is only one way to obtain the same dimension as the weight matrix.</p>

<p>As you may have noticed the partial derivatives follow the same pattern, we did the differentiation manually to see the foundations but we can apply the backpropagation algorithm, for the last layer (l is the index of the last layer) we have:</p>

<script type="math/tex; mode=display">\delta^{(l)} = -(y - a^{(l)})\odot\sigma'(z^{(l)})</script>

<p>For non output layer (l is not the index of the last layer):</p>

<script type="math/tex; mode=display">\delta^{(l)} = ((\delta^{(l + 1)} \cdot W_{(l)}^{\intercal})\odot\sigma'(z^{(l)}))</script>

<p>Then we compute the gradients:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_{(l)}} = a^{(l)\intercal} \cdot \delta^{(l + 1)}</script>

<p>You can stack a bunch of layers and use the backpropagation formula to easily compute the gradients. Let’s use our previous examples to compute our gradients and do a gradient descent iteration.</p>

<script type="math/tex; mode=display">\delta^{(4)} = (y-\hat{y}) \odot - (1-\tanh(Z^{(4)})^2)</script>

<script type="math/tex; mode=display">\delta^{(4)} = \begin{bmatrix}
0.45 \\
0.8 \\
0.2 \\
0.5 \\
0.55 \\
\end{bmatrix}-\begin{bmatrix}
0.202354302599 \\
0.144933682554 \\
0.381054078721 \\
0.262494787219 \\
0.368818057375 \\
\end{bmatrix} \odot - \begin{bmatrix}
0.95905273622 \\
0.978994227661 \\
0.85479778909 \\
0.931096486683 \\
0.863973240554 \\
\end{bmatrix}</script>

<p>We took care of applying 1−tanh⁡(x)2 element wise to Z(4) values.</p>

<script type="math/tex; mode=display">\delta^{(4)} = \begin{bmatrix}
0.247645697401 \\
0.655066317446 \\
-0.181054078721 \\
0.237505212781 \\
0.181181942625 \\
\end{bmatrix} \odot - \begin{bmatrix}
0.95905273622 \\
0.978994227661 \\
0.85479778909 \\
0.931096486683 \\
0.863973240554 \\
\end{bmatrix}</script>

<script type="math/tex; mode=display">\delta^{(4)} = \begin{bmatrix}
-0.237505283705 \\
-0.641306143515 \\
0.154764626197 \\
-0.221140269189 \\
-0.156536350099 \\
\end{bmatrix}</script>

<p>Our gradient for W3 is:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = a^{(3)\intercal} \cdot \delta^{(4)}</script>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_3} = \begin{bmatrix}
0.312422790277 & 0.16852505915 & 0.745005333554 & 0.448044091981 & 0.578398840625 \\
0.226071339877 & 0.0956597075832 & 0.662175586399 & 0.367961400586 & 0.643703471035 \\
1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
\end{bmatrix} \cdot \begin{bmatrix}
-0.237505283705 \\
-0.641306143515 \\
0.154764626197 \\
-0.221140269189 \\
-0.156536350099 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = \begin{bmatrix}
-0.25659878177 \\
-0.194693013848 \\
-1.10172342031 \\
\end{bmatrix}</script>

<p>For W2 we have:</p>

<script type="math/tex; mode=display">\delta^{(3)} = (\delta^{(4)} \cdot W_3^{\intercal}) \odot 1-\tanh(Z^{(3)})^2</script>

<script type="math/tex; mode=display">% <![CDATA[
\delta^{(3)} = \begin{bmatrix}
-0.237505283705 \\
-0.641306143515 \\
0.154764626197 \\
-0.221140269189 \\
-0.156536350099 \\
\end{bmatrix} \cdot \begin{bmatrix}
0.04 & 0.41 & 0.1 \\
\end{bmatrix} \odot \begin{bmatrix}
0.902392000116 & 0.948891749286 & 0.419974341614 \\
0.971599304439 & 0.990849220345 & 0.419974341614 \\
0.444967052977 & 0.561523492777 & 0.419974341614 \\
0.799256491641 & 0.864604407679 & 0.419974341614 \\
0.665454781164 & 0.585645841377 & 0.419974341614 \\
\end{bmatrix} %]]></script>

<p>As before we took care of applying 1−tanh⁡(x)2 element wise to Z(3) values. We also concatenated a column of 1 to Z(3) as described before. The 1s became 0.419974341614 when applying 1−tanh⁡(x)2.</p>

<script type="math/tex; mode=display">% <![CDATA[
\delta^{(3)} = \begin{bmatrix}
-0.0095002113482 & -0.0973771663191 & -0.0237505283705 \\
-0.0256522457406 & -0.262935518841 & -0.0641306143515 \\
0.00619058504786 & 0.0634534967406 & 0.0154764626197 \\
-0.00884561076757 & -0.0906675103676 & -0.0221140269189 \\
-0.00626145400397 & -0.0641799035407 & -0.0156536350099 \\
\end{bmatrix} \odot \begin{bmatrix}
0.902392000116 & 0.948891749286 & 0.419974341614 \\
0.971599304439 & 0.990849220345 & 0.419974341614 \\
0.444967052977 & 0.561523492777 & 0.419974341614 \\
0.799256491641 & 0.864604407679 & 0.419974341614 \\
0.665454781164 & 0.585645841377 & 0.419974341614 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\delta^{(3)} = \begin{bmatrix}
-0.00857291472002 & -0.092400389689 & -0.00997461251539 \\
-0.0249237041189 & -0.260529453845 & -0.0269332125396 \\
0.00275460638495 & 0.0356306291187 & 0.0064997171992 \\
-0.0070699118285 & -0.078391529097 & -0.00928732389571 \\
-0.00416671450398 & -0.0375866936086 & -0.00657412505716 \\
\end{bmatrix} %]]></script>

<p>Our gradient for W2 is:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_2} = a^{(2)\intercal} \cdot \delta^{(3)}</script>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_2} = \begin{bmatrix}
-0.0698858903164 & -0.0917413131084 & 0.113508705786 & -0.0449696495836 & 0.34345116481 \\
0.339033408721 & 0.134185809931 & 0.988329664432 & 0.600545525169 & 0.658975160566 \\
0.139092447878 & 0.0309900734824 & 0.710404487737 & 0.221278467898 & 0.434961731831 \\
1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
\end{bmatrix} \cdot \begin{bmatrix}
-0.00857291472002 & -0.092400389689 \\
-0.0249237041189 & -0.260529453845 \\
0.00275460638495 & 0.0356306291187 \\
-0.0070699118285 & -0.078391529097 \\
-0.00416671450398 & -0.0375866936086 \\
\end{bmatrix} %]]></script>

<p>We took care of removing the last column of δ(3) as the error on the bias is not backpropagated.</p>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_2} = \begin{bmatrix}
0.0020851994346 & 0.0250192301883 \\
-0.010520017991 & -0.102917746604 \\
-0.00338471099243 & -0.0293089952796 \\
-0.0419786387864 & -0.433277437121 \\
\end{bmatrix} %]]></script>

<p>Finally for W1 we have:</p>

<script type="math/tex; mode=display">\delta^{(2)} = (\delta^{(3)} \cdot W_2^{\intercal}) \odot 1-\tanh(Z^{(2)})^2</script>

<script type="math/tex; mode=display">% <![CDATA[
\delta^{(2)} = \begin{bmatrix}
-0.00857291472002 & -0.092400389689 \\
-0.0249237041189 & -0.260529453845 \\
0.00275460638495 & 0.0356306291187 \\
-0.0070699118285 & -0.078391529097 \\
-0.00416671450398 & -0.0375866936086 \\
\end{bmatrix} \cdot \begin{bmatrix}
0.04 & 0.4 & 0.65 & 0.1 \\
0.78 & 0.45 & 0.23 & 0.1 \\
\end{bmatrix} \odot \begin{bmatrix}
0.995115962335 & 0.885056347771 & 0.980653290943 & 0.419974341614 \\
0.991583531469 & 0.981994168413 & 0.999039615346 & 0.419974341614 \\
0.987115773711 & 0.0232044744039 & 0.495325463803 & 0.419974341614 \\
0.997977730616 & 0.6393450722 & 0.951035839645 & 0.419974341614 \\
0.88204129739 & 0.565751737757 & 0.810808291842 & 0.419974341614 \\
\end{bmatrix} %]]></script>

<p>We took care of removing the last column of δ(3), we also concatenated a column of 1 to Z(2) and applied 1−tanh⁡(x)2 element wise to Z(2) values.</p>

<script type="math/tex; mode=display">% <![CDATA[
\delta^{(2)} = \begin{bmatrix}
-0.0724152205462 & -0.0450093412481 & -0.0268244841965 & -0.0100973304409 \\
-0.204209922164 & -0.127207735878 & -0.0761221820616 & -0.0285453157964 \\
0.0279020749679 & 0.0171356256574 & 0.00998553884751 & 0.00383852355036 \\
-0.0614281891688 & -0.0381041528251 & -0.0226254943808 & -0.00854614409256 \\
-0.0294842895948 & -0.0185806979255 & -0.0113533039576 & -0.00417534081126 \\
\end{bmatrix} \odot \begin{bmatrix}
0.995115962335 & 0.885056347771 & 0.980653290943 & 0.419974341614 \\
0.991583531469 & 0.981994168413 & 0.999039615346 & 0.419974341614 \\
0.987115773711 & 0.0232044744039 & 0.495325463803 & 0.419974341614 \\
0.997977730616 & 0.6393450722 & 0.951035839645 & 0.419974341614 \\
0.88204129739 & 0.565751737757 & 0.810808291842 & 0.419974341614 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\delta^{(2)} = \begin{bmatrix}
-0.0720615418815 & -0.0398358031806 & -0.0263055187051 & -0.00424061970398 \\
-0.20249119578 & -0.124917254809 & -0.0760490754861 & -0.0119883002078 \\
0.0275425783201 & 0.000397623186961 & 0.00494609166096 & 0.00161208140083 \\
-0.0613039648226 & -0.0243617023391 & -0.0215176560459 & -0.00358916123861 \\
-0.0260063610469 & -0.0105120621401 & -0.00920535298859 & -0.00175353600822 \\
\end{bmatrix} %]]></script>

<p>Our gradient for W1 is:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_1} = X^{\intercal} \cdot \delta^{(2)}</script>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_1} = \begin{bmatrix}
1.4 & 0.4 & 5.4 & 1.5 & 1.8 \\
-1.0 & -1.0 & -1.0 & -1.0 & 1.0 \\
0.4 & 0.1 & 4.0 & 1.0 & 1.0 \\
1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
\end{bmatrix} \cdot \begin{bmatrix}
-0.0720615418815 & -0.0398358031806 & -0.0263055187051 \\
-0.20249119578 & -0.124917254809 & -0.0760490754861 \\
0.0275425783201 & 0.000397623186961 & 0.00494609166096 \\
-0.0613039648226 & -0.0243617023391 & -0.0215176560459 \\
-0.0260063610469 & -0.0105120621401 & -0.00920535298859 \\
\end{bmatrix} %]]></script>

<p>We took care of removing the last column of δ(2) as the error on the bias is not backpropagated.</p>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_1} = \begin{bmatrix}
-0.171920111136 & -0.159054126528 & -0.0893845808607 \\
0.282307763117 & 0.178205075002 & 0.109720805588 \\
-0.0262137489196 & -0.0617093184844 & -0.0290657574213 \\
-0.334320485211 & -0.199229199282 & -0.128131511565 \\
\end{bmatrix} %]]></script>

<p>Now that we have our gradients, we can apply one iteration of the gradient descent algorithm to update our weights. We saw previously the update formula:</p>

<script type="math/tex; mode=display">W_{(l)} = W_{(l)} - \alpha \frac{1}{n} \frac{\partial J(W)}{\partial W_{(l)}}</script>

<p>We have five cars in our dataset so n=5, we choose a learning rate of α=0.1.</p>

<script type="math/tex; mode=display">W_1 = W_1 - \alpha \frac{1}{n} \frac{\partial J(W)}{\partial W_1}</script>

<script type="math/tex; mode=display">% <![CDATA[
W_1 = \begin{bmatrix}
0.01 & 0.05 & 0.07 \\
0.2 & 0.041 & 0.11 \\
0.04 & 0.56 & 0.13 \\
0.1 & 0.1 & 0.1 \\
\end{bmatrix} - 0.1 \odot \frac{1}{5} \odot \begin{bmatrix}
-0.171920111136 & -0.159054126528 & -0.0893845808607 \\
0.282307763117 & 0.178205075002 & 0.109720805588 \\
-0.0262137489196 & -0.0617093184844 & -0.0290657574213 \\
-0.334320485211 & -0.199229199282 & -0.128131511565 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
W_1 = \begin{bmatrix}
0.0134384022227 & 0.0531810825306 & 0.0717876916172 \\
0.194353844738 & 0.0374358985 & 0.107805583888 \\
0.0405242749784 & 0.56123418637 & 0.130581315148 \\
0.106686409704 & 0.103984583986 & 0.102562630231 \\
\end{bmatrix} %]]></script>

<p>As you can see our weights matrix has been updated, some values are bigger, others smaller, we are moving in our space of solutions toward the best set of weights.</p>

<p>We do the exact same thing for W2 and W3:</p>

<script type="math/tex; mode=display">W_2 = W_2 - \alpha \frac{1}{n} \frac{\partial J(W)}{\partial W_2}</script>

<script type="math/tex; mode=display">% <![CDATA[
W_2 = \begin{bmatrix}
0.04 & 0.78 \\
0.4 & 0.45 \\
0.65 & 0.23 \\
0.1 & 0.1 \\
\end{bmatrix} - 0.1 \odot \frac{1}{5} \odot \begin{bmatrix}
0.0020851994346 & 0.0250192301883 \\
-0.010520017991 & -0.102917746604 \\
-0.00338471099243 & -0.0293089952796 \\
-0.0419786387864 & -0.433277437121 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
W_2 = \begin{bmatrix}
0.0399582960113 & 0.779499615396 \\
0.40021040036 & 0.452058354932 \\
0.65006769422 & 0.230586179906 \\
0.100839572776 & 0.108665548742 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">W_3 = W_3 - \alpha \frac{1}{n} \frac{\partial J(W)}{\partial W_3}</script>

<script type="math/tex; mode=display">W_3 = \begin{bmatrix}
0.04 \\
0.41 \\
0.1 \\
\end{bmatrix} - 0.1 \odot \frac{1}{5} \odot \begin{bmatrix}
-0.25659878177 \\
-0.194693013848 \\
-1.10172342031 \\
\end{bmatrix}</script>

<script type="math/tex; mode=display">W_3 = \begin{bmatrix}
0.0451319756354 \\
0.413893860277 \\
0.122034468406 \\
\end{bmatrix}</script>

<p>By doing the forward propagation, backward propagation and weights update in a loop you have an algorithm that learn.</p>

<h3 id="gradient-checking">Gradient checking</h3>

<p>To do the backpropagation we found the derivative of our cost function. It is easy to do a mistake during the differentiation and while working ostensibly fine our neural network will perform poorly. We used the chain rule to find our gradients, this is called analytical differentiation.</p>

<p>Nonetheless the original definition of a derivative is the following:</p>

<script type="math/tex; mode=display">\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}</script>

<p>The idea is that for a small enough h value the previous formula approximates correctly the value of the derivative of the function f. Because if you zoom enough on a tiny part of the graph of the function, it will appear linear, and so approximate the tangent of the graph. This is called numerical differentiation. As you can see we are computing twice f(x), that’s why the numerical differentiation is slower and not used (even if it is less error prone).</p>

<p>The idea is to use the numerical differentiation to check that our analytical differentiation implementation is correct. We will not use the strict definition but rather the centered formula (works better):</p>

<script type="math/tex; mode=display">\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in}</script>

<p>In total we have three matrices containing the weights. We will test one weight at a time. We will proceed as follow:</p>

<ul>
  <li>We do a forward and backward propagation.</li>
  <li>We save our gradients into a vector V1.</li>
  <li>For each weight:
    <ul>
      <li>We compute f(weight + h).</li>
      <li>We compute f(weight - h).</li>
      <li>We compute the centered formula and save the value into a vector V2.</li>
    </ul>
  </li>
  <li>The difference between V1 and V2 should be less than 10−8.</li>
</ul>

<p>The function that we differentiated during the backpropagation is our cost function:</p>

<script type="math/tex; mode=display">J(W) = \sum_{1}^{n} \frac{1}{2}(y-\hat{y})^2</script>

<p>Where y^ is in reality a(4).</p>

<p>During the backpropagation we found our gradients equal to:</p>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_1} = \begin{bmatrix}
-0.171920111136 & -0.159054126528 & -0.0893845808607 \\
0.282307763117 & 0.178205075002 & 0.109720805588 \\
-0.0262137489196 & -0.0617093184844 & -0.0290657574213 \\
-0.334320485211 & -0.199229199282 & -0.128131511565 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
\frac{\partial J(W)}{\partial W_2} = \begin{bmatrix}
0.0020851994346 & 0.0250192301883 \\
-0.010520017991 & -0.102917746604 \\
-0.00338471099243 & -0.0293089952796 \\
-0.0419786387864 & -0.433277437121 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = \begin{bmatrix}
-0.25659878177 \\
-0.194693013848 \\
-1.10172342031 \\
\end{bmatrix}</script>

<p>We save them into a vector V(1) of size 23×1. These gradients have been computed during the forward pass with the analytical differentiation.</p>

<p>As you will see later in the code I am using a perturbation vector, I will keep the explanation simple and don’t talk about it.</p>

<p>The weights that we used are:</p>

<script type="math/tex; mode=display">% <![CDATA[
W_1 = \begin{bmatrix}
0.0134384022227 & 0.0531810825306 & 0.0717876916172 \\
0.194353844738 & 0.0374358985 & 0.107805583888 \\
0.0405242749784 & 0.56123418637 & 0.130581315148 \\
0.106686409704 & 0.103984583986 & 0.102562630231 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">% <![CDATA[
W_2 = \begin{bmatrix}
0.0399582960113 & 0.779499615396 \\
0.40021040036 & 0.452058354932 \\
0.65006769422 & 0.230586179906 \\
0.100839572776 & 0.108665548742 \\
\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">W_3 = \begin{bmatrix}
0.0451319756354 \\
0.413893860277 \\
0.122034468406 \\
\end{bmatrix}</script>

<p>We disturb the first weight by adding a small value, we choose h=10−4.</p>

<script type="math/tex; mode=display">% <![CDATA[
W_1 = \begin{bmatrix}
0.0134384022227 + 0.0001 & 0.0531810825306 & 0.0717876916172 \\
0.194353844738 & 0.0374358985 & 0.107805583888 \\
0.0405242749784 & 0.56123418637 & 0.130581315148 \\
0.106686409704 & 0.103984583986 & 0.102562630231 \\
\end{bmatrix} %]]></script>

<p>All the other weights stay the same. We do a forward propagation using the weights disturbed (just one value has been disturbed). We obtain:</p>

<script type="math/tex; mode=display">a^{(4)} = \begin{bmatrix}
0.202395039754 \\
0.144946047163 \\
0.381136194829 \\
0.262533502845 \\
0.368843890153 \\
\end{bmatrix}</script>

<p>We compute the sum of the costs (square the cost before summing):</p>

<script type="math/tex; mode=display">J(W) = \frac{1}{2}\sum\left(\begin{bmatrix}
0.45 \\
0.8 \\
0.2 \\
0.5 \\
0.55 \\
\end{bmatrix}-\begin{bmatrix}
0.202395039754 \\
0.144946047163 \\
0.381136194829 \\
0.262533502845 \\
0.368843890153 \\
\end{bmatrix}\right)^2</script>

<script type="math/tex; mode=display">J(W) = loss2 = 0.30621105</script>

<p>We disturb again the first weight by removing the small value h.</p>

<script type="math/tex; mode=display">% <![CDATA[
W_1 = \begin{bmatrix}
0.0134384022227 - 0.0001 & 0.0531810825306 & 0.0717876916172 \\
0.194353844738 & 0.0374358985 & 0.107805583888 \\
0.0405242749784 & 0.56123418637 & 0.130581315148 \\
0.106686409704 & 0.103984583986 & 0.102562630231 \\
\end{bmatrix} %]]></script>

<p>All the other weights stay the same. We do a forward propagation using the weights disturbed (just one value has been disturbed). We obtain:</p>

<script type="math/tex; mode=display">a^{(4)} = \begin{bmatrix}
0.202313563549 \\
0.144921317917 \\
0.380971901463 \\
0.262456067958 \\
0.368792216736 \\
\end{bmatrix}</script>

<p>We also compute the sum of the costs:</p>

<script type="math/tex; mode=display">J(W) = \frac{1}{2}\sum\left(\begin{bmatrix}
0.45 \\
0.8 \\
0.2 \\
0.5 \\
0.55 \\
\end{bmatrix}-\begin{bmatrix}
0.202313563549 \\
0.144921317917 \\
0.380971901463 \\
0.262456067958 \\
0.368792216736 \\
\end{bmatrix}\right)^2</script>

<script type="math/tex; mode=display">J(W) = loss1 = 0.30624543</script>

<p>Then we compute the numerical gradient by doing:</p>

<script type="math/tex; mode=display">V^{(2)}_1 = \frac{(loss2 - loss1)}{(2*h)}</script>

<script type="math/tex; mode=display">V^{(2)}_1 = -0.17192014</script>

<p>This is the first weight computed using the numerical differentiation. Using the analytical differentiation we found −0.171920111136. As you can see they are almost identical.</p>

<p>We repeat the process for each weight until we have computed our 23 numerical gradients into the vector V1(2). We then want to compare our analytical gradients with our numerical gradients. To quantify the difference we divide the norm of the difference by the norm of the sum of the vectors we would like to compare. Typical results should be on the order of 10−8 or less if we’ve computed our gradient correctly.</p>

<script type="math/tex; mode=display">\frac{\left|V^{(1)} - V^{(2)}\right|}{\left|V^{(1)} + V^{(2)}\right|} = 1.15700817288e-08</script>

<p>As you can see the difference is on the order of 10−8 this means that our backward propagation computes correctly the gradients ∇(J(W)). If it is not the case, it means that there is an error in the backpropagation algorithm and you have to debug it, good luck, as you will see, you sometimes lose a great amount of time because of a little mistake.</p>

<h3 id="regularization">Regularization</h3>

<p>One last step is missing, the regularization. During the training our weights will evolve in order to predict correctly the price of a car from its attributes. Nonetheless it could happen that the weights are perfectly predicting the price for the training data but can’t generalize for an unseen car. This problem is called overfitting. During the training steps our network will display a small loss but when testing it with unseen data it will display a larger loss. It means that our weights are well suited for the training data only.</p>

<p>Regularization is useful when the network has a lot of parameters and not enough data. Enough data is at least ten times the number of parameters. Our network has 23 parameters so we need at least 230 cars. As our dataset of cars has more than 9k cars, overfitting is not really a problem for us, nonetheless we will solve the overfitting problem as it regularly occurs.</p>

<p>One way to reduce overfitting is called regularization. The idea is to penalize large weights by modifying our cost function. There are several way to do regularization, the most used are L1, L2, max norm and dropout. We will use the L2 regularization because it is the most common. It is pretty simple, we only add one term to our cost function:</p>

<script type="math/tex; mode=display">J(W) = \sum_{1}^{n}\frac{1}{2}(y-\hat{y})^2 - \frac{1}{2} \lambda \sum_{1}^{3} W_{(n)}^2</script>

<p>The λ is a hyper parameter that will change the impact of the regularization, λ=1 means a strong regularization whereas λ=0.001 means a light regularization. We sum all the weights squared and we add this sum times lambda to the cost function. If the weights are high, the regularization term will be high and the cost will increase, conversely if the weights are low the regularization term will be low.</p>

<p>Because of that, the weights will be smoothed over all the features. If a feature has a strong impact on the price, let’s say the age, the weights corresponding to the age should be high. As we regularize it will not happen. As for the cost function, the regularization term contains 12 to ease things during the differentiation. Previously we differentiated our cost function in order to find our gradients. We did not take into account the regularization term, but the differentiation is easy.</p>

<p>When we expand our regularization sum we have:</p>

<script type="math/tex; mode=display">\frac{1}{2} \lambda \sum_{1}^{3} W_{(n)}^2 = \frac{1}{2} \lambda(W_{(1)}^2 + W_{(2)}^2 + W_{(3)}^2)</script>

<p>When differentiating our cost function w.r.t W(3), we found:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = a^{(3)\intercal} \cdot \delta^{(4)}</script>

<p>If we differentiate the regularization term w.r.t W(3) we have:</p>

<script type="math/tex; mode=display">\frac{1}{2} \lambda(W_{(1)}^2 + W_{(2)}^2 + W_{(3)}^2)</script>

<script type="math/tex; mode=display">\frac{1}{2} \lambda(0 + 0 + W_{(3)}^2)</script>

<script type="math/tex; mode=display">2 \times \frac{1}{2} \lambda W_{(3)}</script>

<script type="math/tex; mode=display">\lambda W_{(3)}</script>

<p>If we add the regularization, our gradient w.r.t W(3) is:</p>

<script type="math/tex; mode=display">\frac{\partial J(W)}{\partial W_3} = a^{(3)\intercal} \cdot \delta^{(4)} - \lambda \cdot W_{(3)}</script>

<p>The process is the same for the gradient w.r.t each weight matrix. We remove from the gradient λ⋅W(n). This means that during each gradient descent iteration, using the L2 regularization, each weight will linearly decay towards zero.</p>

<p>When building a model, here is the list of things you have to choose:</p>

<ul>
  <li>The number of hidden layers</li>
  <li>The number of neurons for each hidden layer</li>
  <li>The activation function</li>
  <li>The cost function</li>
  <li>The optimization algorithm</li>
  <li>The learning rate</li>
  <li>The type of regularization</li>
  <li>The regularization rate</li>
  <li>The number of gradient descent steps</li>
  <li>The way of evaluating the accuracy of the network</li>
</ul>

<p>We saw the theoritical part of a deep neural network, there are other types of neural network that will be the topic of other blog posts. To name a few: Convolutionnal Neural Network, Long Short Term Memory, Generative Adversarial Networks…</p>

<h3 id="python-code">Python code</h3>

<p>We are finally done with the theoritical part. We will now implement all the stuffs we described in python. We will make a first version using only numpy and a second one using TensorFlow. In a following blog post, we will build a version using CuDNN and TensorFlow C++.</p>

<p>All the following code is available on github.</p>

<h4 id="normalization">Normalization</h4>

<p>The first step is to download the data from leboncoin.fr, I made a python script that loads each car page and save for each car its number of kilometers, type of fuel, age and price. The data are saved into a csv file. We have 8717 cars.</p>

<p><img src="/assets/images/notes-on-nn/dataset.png" alt="" /></p>

<p>We have the raw input data, normalize_lbc_cars_data.py will normalize these raw data as we described previously. For the kilometers and the age, we substract the mean and divide by the standard deviation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># normalize kilometers: (x - mean)/std</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"int"</span><span class="p">)</span>
<span class="n">mean_km</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">km</span><span class="p">)</span>
<span class="n">std_km</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">km</span><span class="p">)</span>
<span class="n">km</span> <span class="o">=</span> <span class="p">(</span><span class="n">km</span> <span class="o">-</span> <span class="n">mean_km</span><span class="p">)</span><span class="o">/</span><span class="n">std_km</span>
<span class="n">features</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">km</span>

<span class="c"># normalize age: (x - mean)/std</span>
<span class="n">age</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"int"</span><span class="p">)</span>
<span class="n">mean_age</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">age</span><span class="p">)</span>
<span class="n">std_age</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">age</span><span class="p">)</span>
<span class="n">age</span> <span class="o">=</span> <span class="p">(</span><span class="n">age</span> <span class="o">-</span> <span class="n">mean_age</span><span class="p">)</span><span class="o">/</span><span class="n">std_age</span>
<span class="n">features</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">age</span>
</code></pre></div></div>

<p>For the type of fuel, we binary encode, diesel equals -1, essence equals 1:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># binary convert fuel: Diesel = -1, Essence = 1</span>
<span class="n">features</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s">'Diesel'</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">features</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]]</span>
</code></pre></div></div>

<p>And finally for the price, we bring the data between [0, 1] because it will be the output of our network.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># normalize price: (x - min)/(max - min)</span>
<span class="n">price</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
<span class="n">min_price</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">min</span><span class="p">(</span><span class="n">price</span><span class="p">)</span>
<span class="n">max_price</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">price</span><span class="p">)</span>
<span class="n">features</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">price</span> <span class="o">-</span> <span class="n">min_price</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">max_price</span> <span class="o">-</span> <span class="n">min_price</span><span class="p">)</span>
</code></pre></div></div>

<p>Using the normalized data we create a new CSV file called normalized_car_features.csv. The first line contains mean_km, std_km, mean_age, std_age, min_price, max_price. We will use these data in the future when predicting. The user will input the raw car attributes, we will normalize them so that our network can use them and produce a result, than we will also process this result so that the user can see a price that looks like 13 456 euros and not 0.12789.</p>

<p>During the normalization process we skipped some lines that had a bad format or wrong data. Be careful if you are using the CSV file of raw data.</p>

<h4 id="using-numpy">Using numpy</h4>

<p>The first step is to implement our network using numpy. We implement each part of the neural network described previously. The corresponding code is dnn_from_scratch.py.</p>

<p>We load our normalized data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">"normalized_car_features.csv"</span><span class="p">,</span> <span class="s">"rb"</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</code></pre></div></div>

<p>We shuffle the array because we will keep 80% for our data for the training set and 20% for the test set. The goal is to train our network using the training set and analyze the loss using the test set. If the loss is low with our test set, it means that our network generalizes well because it predicts correctly unseen data.</p>

<p>We split the car attributes and the car prices in two matrices. We also append 1 to each car for the bias unit.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">features</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data_y</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">:]</span>
</code></pre></div></div>

<p>We save the dataset metadata for the prediction part of the network, it will help us to normalize the input that we will predict and convert the output of the network into a human readable price. All the metadata are on the first line of the dataset (mean_km, std_km, mean_age, std_age, min_price, max_price).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">predict</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">Predict</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">4</span><span class="p">]),</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">5</span><span class="p">]))</span>
</code></pre></div></div>

<p>We calculate how many elements 80% of our network means and split the dataset into a train set and a test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>

<span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">data_x</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span><span class="p">,</span> <span class="p">:],</span> <span class="n">data_x</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span><span class="p">:,</span> <span class="p">:]</span>
<span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">data_y</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span><span class="p">,</span> <span class="p">:],</span> <span class="n">data_y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span><span class="p">:,</span> <span class="p">:]</span>
</code></pre></div></div>

<p>We init all the matrices that we will use, also Lambda that is the regularization rate and the learning rate.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">z2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">z4</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a4</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">6</span>
<span class="bp">self</span><span class="o">.</span><span class="n">delta2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta4</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">3</span>
<span class="bp">self</span><span class="o">.</span><span class="n">djdw1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw3</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">3</span>
<span class="bp">self</span><span class="o">.</span><span class="n">gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">numericalGradient</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
</code></pre></div></div>

<p>We init the weights with the values described in the blog post.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.041</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.56</span><span class="p">,</span> <span class="mf">0.13</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<span class="p">])</span>

<span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.78</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<span class="p">])</span>

<span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.04</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.41</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">]</span>
<span class="p">])</span>
</code></pre></div></div>

<p>Once the network is initialized, we can begin the forward propagation. We do the calculations explained in the blog post. We put them into a forward method because we will call them repeatedly during the gradient descent.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

    <span class="c"># first layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z2</span><span class="p">)</span>

    <span class="c"># we add the the 1 unit (bias) at the output of the first layer</span>
    <span class="n">ba2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">a2</span><span class="p">,</span> <span class="n">ba2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c"># second layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">z3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z3</span><span class="p">)</span>

    <span class="c"># we add the the 1 unit (bias) at the output of the second layer</span>
    <span class="n">ba3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">a3</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">a3</span><span class="p">,</span> <span class="n">ba3</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c"># output layer, prediction of our network</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">z4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">a4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z4</span><span class="p">)</span>
</code></pre></div></div>

<p>Then we do the backward propagation, we are using the data computed during the forward propagation to compute the gradients. As the backward propagation gives us the sum of the gradients we divide them by the size of our train set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

    <span class="c"># gradient of the cost function with regards to W3</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delta4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">a4</span><span class="p">),</span> <span class="n">tanh_prime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z4</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">djdw3</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a3</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta4</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3</span>

    <span class="c"># gradient of the cost function with regards to W2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delta3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delta4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">tanh_prime</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">z3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">z3</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">djdw2</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a2</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delta3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span>

    <span class="c"># gradient of the cost function with regards to W1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">delta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delta3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">tanh_prime</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">z2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">z2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">djdw1</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delta2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span>
</code></pre></div></div>

<p>Where tanh_prime is the derivative of the tanh function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">tanh_prime</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<p>The backward propagation gives us the gradients of our cost function, we can use them to update our weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">update_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw3</span>
</code></pre></div></div>

<p>By doing these three steps several times, our network is learning. We choose 5000 steps.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nb_it</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nb_it</span><span class="p">):</span>

    <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">update_gradient</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
</code></pre></div></div>

<p>The summary method gives us the scores regarding our network. I don’t detail here the R2 score method.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Iteration: </span><span class="si">%</span><span class="s">d, Loss </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_function</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"RMSE: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a4</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)))))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"MAE: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a4</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"R2: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">r2</span><span class="p">()))</span>
</code></pre></div></div>

<p>To be sure that our backpropagation algorithm computes the gradients (partial derivatives) of our cost function correctly we use gradient checking. We compute the gradients using the forward and backward propagation, then we compute them using the numerical gradient and we compare both results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">check_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">compute_numerical_gradients</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Gradient checked: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">numericalGradient</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">numericalGradient</span><span class="p">)))</span>
</code></pre></div></div>

<p>The compute_gradient method is pretty simple, we save our three gradient matrices produced by the forward and backward prop into one [1 x 23] vector.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">djdw1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw2</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">djdw3</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</code></pre></div></div>

<p>The compute_numerical_gradients method is more complicated. To add or remove the perturbation as we described earlier our weights are flattened into one vector of size [1 x 23]. We test each weight separately. We have a perturbation vector of the same size [1 x 23] containing zeros everywhere except at the index of the weight that we are testing.</p>

<p>If we are testing the 5th weight, our perturbation vector will have 1e-4 at the 5th position. We add the perturbation vector to the weights, then we reconstruct our three weights matrices do a forward pass and compute the cost. Then we remove the perturbation vector from the weights, reconstruct our three weights matrices, do a forward pass and compute the cost. Our numerical gradient for the 5th weight is given by: (loss2 - loss1) / (2 * e). We do that for each weight. We obtain a [1 x 23] vector containing each numerical gradient for each weight.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_numerical_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">numericalGradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">perturbation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="mf">1e-4</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)):</span>
        <span class="c"># Set perturbation vector</span>
        <span class="n">perturbation</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">e</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span> <span class="o">+</span> <span class="n">perturbation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
        <span class="n">loss2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_function</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span> <span class="o">-</span> <span class="n">perturbation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
        <span class="n">loss1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_function</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">numericalGradient</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss2</span> <span class="o">-</span> <span class="n">loss1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">e</span><span class="p">)</span>

        <span class="n">perturbation</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></div>

<p>The cost function method used in the code above is the implementation of our cost function. As the cost function gives us the sum of the cost we divide it by the size of our train set:</p>

<script type="math/tex; mode=display">J(W) = \sum_{1}^{n} \frac{1}{2}(y-\hat{y})^2 - \frac{1}{2} \lambda \sum_{1}^{3} W_{(n)}^2</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">a4</span><span class="p">)))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_train_set</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Lambda</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">))</span> <span class="o">+</span>
        <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">))</span> <span class="o">+</span>
        <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w3</span><span class="p">))</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>The only difference compared to the formula is that the cost is averaged for all the training examples (because the gradients are averaged too, remember the 1n when we update the weights using the gradients). The set_weights method is useful to convert the weights from one [1 x 23] vector to three matrices back and forth.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">12</span><span class="p">],</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">12</span><span class="p">:</span><span class="mi">20</span><span class="p">],</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="mi">23</span><span class="p">],</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>For the regularization there is no explicit part in the code, you can see that we add the regularization term to the cost function + (self.Lambda / 2) * (np.sum(np.square(self.w1)) + np.sum(np.square(self.w2)) + np.sum(np.square(self.w3))), also when computing the gradients we add the weights times lambda (due to the differentiation process) + self.Lambda * self.w3 for each weight matrix.</p>

<p>If you remember we splitted our data between train set and test set. We want the network’s summary (the metrics) with the test set, after 5000 iterations we have:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">### Testing summary ###</span>
<span class="n">Iteration</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">Loss</span> <span class="mf">0.004642</span>
<span class="n">RMSE</span><span class="p">:</span> <span class="mf">0.0459143540873</span>
<span class="n">MAE</span><span class="p">:</span> <span class="mf">0.00770927707759</span>
<span class="n">R2</span><span class="p">:</span> <span class="mf">0.662649615919</span>
</code></pre></div></div>

<p>Our R2 score could be better, but overall, given the number of features for a car (only 3) and the small size of our network, the results are pretty good.</p>

<p>Now let’s predict the price of a car. We introduced a helper class called Predict available into predict.py. Our predict object is constructed during the init part of the neural network, it only saves the metadata of our dataset, meaning: mean_km, std_km, mean_age, std_age, min_price, max_price. We then use the predict object to convert real life car attributes into a normalized version, so that our network can use them. Our predict object is also useful to convert the output of the network into a human readable price.</p>

<p>To use our network to predict a price, we only need to do a forward pass where X, the input, contains the car’s data for which we want to predict the price. This is called inference, and it will use our previously learned weights.</p>

<p>I took a random ads where a 5 years old car with 168000 kilometers and a Diesel engine was sold 16 000 euros.</p>

<p>Once the training steps are done, to predict the price we run the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"### Predict ###"</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">predict_price</span><span class="p">(</span><span class="mi">168000</span><span class="p">,</span> <span class="s">"Diesel"</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<p>Where predict_price is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict_price</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">km</span><span class="p">,</span> <span class="n">fuel</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="o">.</span><span class="nb">input</span><span class="p">(</span><span class="n">km</span><span class="p">,</span> <span class="n">fuel</span><span class="p">,</span> <span class="n">age</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Predicted price: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a4</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
</code></pre></div></div>

<p>self.predict.input(km, fuel, age) will took the raw car attributes and give us the normalized version to which we append 1 for the bias.</p>

<p>We then do a forward pass and the predicted price is Predicted price: [[ 13484.89728828]]</p>

<p>16 000 euros seems expensive according to our network.</p>

<h4 id="using-tensorflow">Using TensorFlow</h4>

<p>We also implemented the same version of our network using TensorFlow. The code is easier because TF do things for you. Namely the whole optimization part. The corresponding code is dnn_from_scratch_tensorflow.py.</p>

<p>The idea of TF is that you build a graph in python and then once your graph is ready, you run it. The computation begins when the session is run, before it is only a graph definition. We are using the same normalized data as previously. Reading the CSV is the same code as before.</p>

<p>The Github code contains with statements that are useful to group nodes under a same group when displaying the graph in TensorBoard, the name passed as parameter for each TF operation is also used by TensorBoard to name nodes beautifully. I will omit them here in order to keep the code clear.</p>

<p>We declare our variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">"float"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"cars"</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">"float"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"prices"</span><span class="p">)</span>

<span class="n">w1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s">"W1"</span><span class="p">)</span>
<span class="n">w2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s">"W2"</span><span class="p">)</span>
<span class="n">w3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s">"W3"</span><span class="p">)</span>

<span class="n">b1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s">"b1"</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s">"b2"</span><span class="p">)</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s">"b3"</span><span class="p">)</span>
</code></pre></div></div>

<p>A placeholder will be completed when the session is run, the variables are initialized by randomly choosing data from a normal distribution.</p>

<p>Then we declare our execution graph. We separate the weights and the bias whereas in our previous examples we merged them. TensorFlow manages them separately. We define our three layers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">layer_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w1</span><span class="p">),</span> <span class="n">b1</span><span class="p">))</span>
<span class="n">layer_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">w2</span><span class="p">),</span> <span class="n">b2</span><span class="p">))</span>
<span class="n">layer_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layer_2</span><span class="p">,</span> <span class="n">w3</span><span class="p">),</span>  <span class="n">b3</span><span class="p">))</span>
</code></pre></div></div>

<p>We compute the regularization. The sum of the L2 loss of each weight matrix.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regularization</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_loss</span><span class="p">(</span><span class="n">w1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_loss</span><span class="p">(</span><span class="n">w2</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_loss</span><span class="p">(</span><span class="n">w3</span><span class="p">)</span>
</code></pre></div></div>

<p>We define our cost function (to which we add the regularization).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">layer_3</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span> <span class="o">+</span> <span class="n">Lambda</span> <span class="o">*</span> <span class="n">regularization</span>
</code></pre></div></div>

<p>We then define which algorithm we will use to minimize our cost function. We choose gradient descent and specify that the loss operation will be minimized. The loss operation is our cost function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<p>We defined the learning rate to 0.01. We can then train the network for 5000 steps.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># launching the previously defined model begins here</span>
<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_data</span><span class="p">})</span>
</code></pre></div></div>

<p>Our feed_dict contains the data by which the placeholders will be replaced. x_data contains the training data, meaning 80% of our data set, these data will be used when the placeholder x is used in our graph. y_data contains the prices of our cars.</p>

<p>The great thing about TensorFlow is that it knows which operations we stacked during our graph definition and how to differentiate each one of them. As we called GradientDescentOptimizer(learning_rate).minimize(loss) TF knows that the backward propagation will start from the loss formula back to the input and that it has to differentiate the whole calculation graph.</p>

<p>When coding the network, the back propagation part is the most error prone. We don’t check our gradient here, we assume that TF is unit tested and that the analytical differentiation of our cost function is correct.</p>

<p>We use our testing data to validate the performances of our network. At the 5000th iteration our training set gives a loss of: 0.024727896 and our test set gives a loss of: 0.024568973 which is good.</p>

<p>If we try to predict the same car as before, TensorFlow gives us a price of Predicted price: [[ 13471.90332031]]. We also do a forward pass using one input:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">predict</span><span class="o">.</span><span class="nb">input</span><span class="p">(</span><span class="mi">168000</span><span class="p">,</span> <span class="s">"Diesel"</span><span class="p">,</span> <span class="mi">5</span><span class="p">)}</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Predicted price: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">predict</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">layer_3</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">))))</span>
</code></pre></div></div>

<p>As with our numpy network, the price is less than 16 000 euros. Definitely overpriced. Each launch will give a different price because we are learning the weights from scratch each time and they are randomly initialized.</p>

<p>Thanks for reading this post, if you have questions or see mistakes, do not hesitate to comment.</p>

<h2 id="полезные-ресурсы">Полезные ресурсы</h2>

<ul>
  <li>Курс Андрея Созыкина</li>
  <li>Книга Нейронные сети и глубокое обучение</li>
  <li>Книга Николенко Глубокое обучение</li>
  <li>Стенфордский курс</li>
  <li>Курс Нг на курсере</li>
</ul>

  </div>

  
    <div class="post-comments" itemprop="comment">
      

    </div>
  

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy;  - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="https://dementiy.github.io/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
